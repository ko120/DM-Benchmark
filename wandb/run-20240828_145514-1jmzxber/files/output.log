
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /local/scratch/a/ko120/DM-Benchmark/checkpoints exists and is not empty.
[[36m2024-08-28 14:55:16,973[39m][[34msrc.training_pipeline[39m][[32mINFO[39m] - Starting training!
[[36m2024-08-28 14:55:17,008[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[[36m2024-08-28 14:55:17,010[39m][[34mpytorch_lightning.accelerators.cuda[39m][[32mINFO[39m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃[1m    [22m┃[1m Name                    [22m┃[1m Type                                 [22m┃[1m Params [22m┃[1m Mode  [22m┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0  │ net                     │ MLP                                  │ 93.2 K │ train │
│ 1  │ net.hiddens             │ ModuleList                           │ 93.2 K │ train │
│ 2  │ net.hiddens.0           │ Linear                               │ 26.9 K │ train │
│ 3  │ net.hiddens.1           │ Linear                               │ 65.8 K │ train │
│ 4  │ net.hiddens.2           │ Linear                               │    514 │ train │
│ 5  │ train_acc               │ BinaryAccuracy                       │      0 │ train │
│ 6  │ val_acc                 │ BinaryAccuracy                       │      0 │ train │
│ 7  │ test_acc                │ BinaryAccuracy                       │      0 │ train │
│ 8  │ train_ece               │ MulticlassCalibrationError           │      0 │ train │
│ 9  │ val_ece                 │ MulticlassCalibrationError           │      0 │ train │
│ 10 │ test_ece                │ MulticlassCalibrationError           │      0 │ train │
│ 11 │ train_entropy           │ ShannonEntropyError                  │      0 │ train │
│ 12 │ val_entropy             │ ShannonEntropyError                  │      0 │ train │
│ 13 │ test_entropy            │ ShannonEntropyError                  │      0 │ train │
│ 14 │ test_kcal               │ ClassificationKernelCalibrationError │      0 │ train │
│ 15 │ val_acc_best            │ MaxMetric                            │      0 │ train │
│ 16 │ val_ece_best            │ MinMetric                            │      0 │ train │
│ 17 │ val_entropy_best        │ MinMetric                            │      0 │ train │
│ 18 │ test_calibrated_acc     │ BinaryAccuracy                       │      0 │ train │
│ 19 │ test_calibrated_ece     │ MulticlassCalibrationError           │      0 │ train │
│ 20 │ test_calibrated_entropy │ ShannonEntropyError                  │      0 │ train │
│ 21 │ test_calibrated_kcal    │ ClassificationKernelCalibrationError │      0 │ train │
└────┴─────────────────────────┴──────────────────────────────────────┴────────┴───────┘
[1mTrainable params[22m: 93.2 K
[1mNon-trainable params[22m: 0
[1mTotal params[22m: 93.2 K
[1mTotal estimated model params size (MB)[22m: 0
[1mModules in train mode[22m: 22
[1mModules in eval mode[22m: 0
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The
'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to
`num_workers=23` in the `DataLoader` to improve performance.
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(68)__call__()
-> for op in self.operands:
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(69)__call__()
-> scaler = self.scalers[op]
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(70)__call__()
-> bandwidth = self.bandwidths[op]
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(71)__call__()
-> if op == 'x':
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(73)__call__()
-> assert x.dim() == 2
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(74)__call__()
-> loss_mat = loss_mat2 = loss_mat3 = scaler * self.kernel_fun[op](x, x, bandwidth)
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(94)__call__()
-> for i, value in enumerate([loss_mat, loss_mat2, loss_mat3]):
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(95)__call__()
-> if loss_mats[i] is None:
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(96)__call__()
-> loss_mats[i] = value
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(94)__call__()
-> for i, value in enumerate([loss_mat, loss_mat2, loss_mat3]):
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(95)__call__()
-> if loss_mats[i] is None:
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(96)__call__()
-> loss_mats[i] = value
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(94)__call__()
-> for i, value in enumerate([loss_mat, loss_mat2, loss_mat3]):
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(95)__call__()
-> if loss_mats[i] is None:
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(96)__call__()
-> loss_mats[i] = value
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(94)__call__()
-> for i, value in enumerate([loss_mat, loss_mat2, loss_mat3]):
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(68)__call__()
-> for op in self.operands:
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(69)__call__()
-> scaler = self.scalers[op]
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(70)__call__()
-> bandwidth = self.bandwidths[op]
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(71)__call__()
-> if op == 'x':
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(75)__call__()
-> elif op == 'y':
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(77)__call__()
-> num_classes = logits.shape[-1]
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(78)__call__()
-> y_all = torch.eye(num_classes).to(logits.device)
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(79)__call__()
-> k_yy = self.kernel_fun[op](y_all, y_all, bandwidth)
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(80)__call__()
-> q_y = F.softmax(logits, dim=-1)
[1m([22mPdb[1m)
tensor([[1., 0.],
        [0., 1.]], device='cuda:0')
[1m([22mPdb[1m)
tensor([[1., 0.],
        [0., 1.]], device='cuda:0')
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(81)__call__()
-> q_yy = torch.einsum('ic,jd->ijcd', q_y, q_y)
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(82)__call__()
-> total_yy = q_yy * k_yy.unsqueeze(0)
[1m([22mPdb[1m)
tensor([[[[0.2497, 0.2500],
          [0.2500, 0.2503]],
         [[0.2500, 0.2497],
          [0.2503, 0.2500]],
         [[0.2500, 0.2497],
          [0.2503, 0.2500]],
         [[0.2497, 0.2500],
          [0.2500, 0.2503]],
         [[0.2852, 0.2145],
          [0.2856, 0.2147]],
         [[0.2500, 0.2497],
          [0.2503, 0.2500]],
         [[0.2499, 0.2498],
          [0.2502, 0.2501]],
         [[0.2498, 0.2499],
          [0.2501, 0.2502]]],
        [[[0.2500, 0.2503],
          [0.2497, 0.2500]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2500, 0.2503],
          [0.2497, 0.2500]],
         [[0.2856, 0.2147],
          [0.2852, 0.2145]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2502, 0.2501],
          [0.2499, 0.2498]],
         [[0.2501, 0.2502],
          [0.2498, 0.2499]]],
        [[[0.2500, 0.2503],
          [0.2497, 0.2500]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2504, 0.2500],
          [0.2500, 0.2496]],
         [[0.2500, 0.2504],
          [0.2496, 0.2500]],
         [[0.2856, 0.2148],
          [0.2852, 0.2144]],
         [[0.2503, 0.2501],
          [0.2499, 0.2497]],
         [[0.2503, 0.2501],
          [0.2499, 0.2497]],
         [[0.2502, 0.2502],
          [0.2498, 0.2498]]],
        [[[0.2497, 0.2500],
          [0.2500, 0.2503]],
         [[0.2500, 0.2497],
          [0.2503, 0.2500]],
         [[0.2500, 0.2496],
          [0.2504, 0.2500]],
         [[0.2496, 0.2500],
          [0.2500, 0.2504]],
         [[0.2852, 0.2144],
          [0.2856, 0.2148]],
         [[0.2499, 0.2497],
          [0.2503, 0.2501]],
         [[0.2499, 0.2497],
          [0.2503, 0.2501]],
         [[0.2498, 0.2498],
          [0.2502, 0.2502]]],
        [[[0.2852, 0.2856],
          [0.2145, 0.2147]],
         [[0.2856, 0.2852],
          [0.2147, 0.2145]],
         [[0.2856, 0.2852],
          [0.2148, 0.2144]],
         [[0.2852, 0.2856],
          [0.2144, 0.2148]],
         [[0.3258, 0.2450],
          [0.2450, 0.1842]],
         [[0.2855, 0.2853],
          [0.2147, 0.2145]],
         [[0.2855, 0.2853],
          [0.2147, 0.2145]],
         [[0.2854, 0.2854],
          [0.2146, 0.2146]]],
        [[[0.2500, 0.2503],
          [0.2497, 0.2500]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2503, 0.2499],
          [0.2501, 0.2497]],
         [[0.2499, 0.2503],
          [0.2497, 0.2501]],
         [[0.2855, 0.2147],
          [0.2853, 0.2145]],
         [[0.2502, 0.2500],
          [0.2500, 0.2498]],
         [[0.2502, 0.2500],
          [0.2500, 0.2498]],
         [[0.2501, 0.2501],
          [0.2499, 0.2499]]],
        [[[0.2499, 0.2502],
          [0.2498, 0.2501]],
         [[0.2502, 0.2499],
          [0.2501, 0.2498]],
         [[0.2503, 0.2499],
          [0.2501, 0.2497]],
         [[0.2499, 0.2503],
          [0.2497, 0.2501]],
         [[0.2855, 0.2147],
          [0.2853, 0.2145]],
         [[0.2502, 0.2500],
          [0.2500, 0.2498]],
         [[0.2502, 0.2500],
          [0.2500, 0.2498]],
         [[0.2501, 0.2501],
          [0.2499, 0.2499]]],
        [[[0.2498, 0.2501],
          [0.2499, 0.2502]],
         [[0.2501, 0.2498],
          [0.2502, 0.2499]],
         [[0.2502, 0.2498],
          [0.2502, 0.2498]],
         [[0.2498, 0.2502],
          [0.2498, 0.2502]],
         [[0.2854, 0.2146],
          [0.2854, 0.2146]],
         [[0.2501, 0.2499],
          [0.2501, 0.2499]],
         [[0.2501, 0.2499],
          [0.2501, 0.2499]],
         [[0.2500, 0.2500],
          [0.2500, 0.2500]]]], device='cuda:0')
[1m([22mPdb[1m)
torch.Size([8, 2])
[1m([22mPdb[1m)
torch.Size([8, 8, 2, 2])
[1m([22mPdb[1m)
tensor([[-0.0069, -0.0057],
        [-0.0029, -0.0040],
        [-0.0004, -0.0020],
        [-0.0023, -0.0008],
        [ 0.2789, -0.0063],
        [-0.0020, -0.0030],
        [-0.0022, -0.0029],
        [-0.0017, -0.0016]], device='cuda:0')
[1m([22mPdb[1m)
tensor([[0.4997, 0.5003],
        [0.5003, 0.4997],
        [0.5004, 0.4996],
        [0.4996, 0.5004],
        [0.5708, 0.4292],
        [0.5002, 0.4998],
        [0.5002, 0.4998],
        [0.5000, 0.5000]], device='cuda:0')
[1m([22mPdb[1m)
tensor([[[0.2497, 0.2500],
         [0.2500, 0.2503]],
        [[0.2500, 0.2497],
         [0.2503, 0.2500]],
        [[0.2500, 0.2497],
         [0.2503, 0.2500]],
        [[0.2497, 0.2500],
         [0.2500, 0.2503]],
        [[0.2852, 0.2145],
         [0.2856, 0.2147]],
        [[0.2500, 0.2497],
         [0.2503, 0.2500]],
        [[0.2499, 0.2498],
         [0.2502, 0.2501]],
        [[0.2498, 0.2499],
         [0.2501, 0.2502]]], device='cuda:0')
[1m([22mPdb[1m)
tensor([[1., 0.],
        [0., 1.]], device='cuda:0')
[1m([22mPdb[1m)
tensor([[[[0.2497, 0.2500],
          [0.2500, 0.2503]],
         [[0.2500, 0.2497],
          [0.2503, 0.2500]],
         [[0.2500, 0.2497],
          [0.2503, 0.2500]],
         [[0.2497, 0.2500],
          [0.2500, 0.2503]],
         [[0.2852, 0.2145],
          [0.2856, 0.2147]],
         [[0.2500, 0.2497],
          [0.2503, 0.2500]],
         [[0.2499, 0.2498],
          [0.2502, 0.2501]],
         [[0.2498, 0.2499],
          [0.2501, 0.2502]]],
        [[[0.2500, 0.2503],
          [0.2497, 0.2500]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2500, 0.2503],
          [0.2497, 0.2500]],
         [[0.2856, 0.2147],
          [0.2852, 0.2145]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2502, 0.2501],
          [0.2499, 0.2498]],
         [[0.2501, 0.2502],
          [0.2498, 0.2499]]],
        [[[0.2500, 0.2503],
          [0.2497, 0.2500]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2504, 0.2500],
          [0.2500, 0.2496]],
         [[0.2500, 0.2504],
          [0.2496, 0.2500]],
         [[0.2856, 0.2148],
          [0.2852, 0.2144]],
         [[0.2503, 0.2501],
          [0.2499, 0.2497]],
         [[0.2503, 0.2501],
          [0.2499, 0.2497]],
         [[0.2502, 0.2502],
          [0.2498, 0.2498]]],
        [[[0.2497, 0.2500],
          [0.2500, 0.2503]],
         [[0.2500, 0.2497],
          [0.2503, 0.2500]],
         [[0.2500, 0.2496],
          [0.2504, 0.2500]],
         [[0.2496, 0.2500],
          [0.2500, 0.2504]],
         [[0.2852, 0.2144],
          [0.2856, 0.2148]],
         [[0.2499, 0.2497],
          [0.2503, 0.2501]],
         [[0.2499, 0.2497],
          [0.2503, 0.2501]],
         [[0.2498, 0.2498],
          [0.2502, 0.2502]]],
        [[[0.2852, 0.2856],
          [0.2145, 0.2147]],
         [[0.2856, 0.2852],
          [0.2147, 0.2145]],
         [[0.2856, 0.2852],
          [0.2148, 0.2144]],
         [[0.2852, 0.2856],
          [0.2144, 0.2148]],
         [[0.3258, 0.2450],
          [0.2450, 0.1842]],
         [[0.2855, 0.2853],
          [0.2147, 0.2145]],
         [[0.2855, 0.2853],
          [0.2147, 0.2145]],
         [[0.2854, 0.2854],
          [0.2146, 0.2146]]],
        [[[0.2500, 0.2503],
          [0.2497, 0.2500]],
         [[0.2503, 0.2500],
          [0.2500, 0.2497]],
         [[0.2503, 0.2499],
          [0.2501, 0.2497]],
         [[0.2499, 0.2503],
          [0.2497, 0.2501]],
         [[0.2855, 0.2147],
          [0.2853, 0.2145]],
         [[0.2502, 0.2500],
          [0.2500, 0.2498]],
         [[0.2502, 0.2500],
          [0.2500, 0.2498]],
         [[0.2501, 0.2501],
          [0.2499, 0.2499]]],
        [[[0.2499, 0.2502],
          [0.2498, 0.2501]],
         [[0.2502, 0.2499],
          [0.2501, 0.2498]],
         [[0.2503, 0.2499],
          [0.2501, 0.2497]],
         [[0.2499, 0.2503],
          [0.2497, 0.2501]],
         [[0.2855, 0.2147],
          [0.2853, 0.2145]],
         [[0.2502, 0.2500],
          [0.2500, 0.2498]],
         [[0.2502, 0.2500],
          [0.2500, 0.2498]],
         [[0.2501, 0.2501],
          [0.2499, 0.2499]]],
        [[[0.2498, 0.2501],
          [0.2499, 0.2502]],
         [[0.2501, 0.2498],
          [0.2502, 0.2499]],
         [[0.2502, 0.2498],
          [0.2502, 0.2498]],
         [[0.2498, 0.2502],
          [0.2498, 0.2502]],
         [[0.2854, 0.2146],
          [0.2854, 0.2146]],
         [[0.2501, 0.2499],
          [0.2501, 0.2499]],
         [[0.2501, 0.2499],
          [0.2501, 0.2499]],
         [[0.2500, 0.2500],
          [0.2500, 0.2500]]]], device='cuda:0')
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(84)__call__()
-> k_yj = k_yy[:,y].T
[1m([22mPdb[1m)
[1m([22mPdb[1m)
tensor([[[[0.2497, 0.0000],
          [0.0000, 0.2503]],
         [[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2497, 0.0000],
          [0.0000, 0.2503]],
         [[0.2852, 0.0000],
          [0.0000, 0.2147]],
         [[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2499, 0.0000],
          [0.0000, 0.2501]],
         [[0.2498, 0.0000],
          [0.0000, 0.2502]]],
        [[[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2503, 0.0000],
          [0.0000, 0.2497]],
         [[0.2503, 0.0000],
          [0.0000, 0.2497]],
         [[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2856, 0.0000],
          [0.0000, 0.2145]],
         [[0.2503, 0.0000],
          [0.0000, 0.2497]],
         [[0.2502, 0.0000],
          [0.0000, 0.2498]],
         [[0.2501, 0.0000],
          [0.0000, 0.2499]]],
        [[[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2503, 0.0000],
          [0.0000, 0.2497]],
         [[0.2504, 0.0000],
          [0.0000, 0.2496]],
         [[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2856, 0.0000],
          [0.0000, 0.2144]],
         [[0.2503, 0.0000],
          [0.0000, 0.2497]],
         [[0.2503, 0.0000],
          [0.0000, 0.2497]],
         [[0.2502, 0.0000],
          [0.0000, 0.2498]]],
        [[[0.2497, 0.0000],
          [0.0000, 0.2503]],
         [[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2496, 0.0000],
          [0.0000, 0.2504]],
         [[0.2852, 0.0000],
          [0.0000, 0.2148]],
         [[0.2499, 0.0000],
          [0.0000, 0.2501]],
         [[0.2499, 0.0000],
          [0.0000, 0.2501]],
         [[0.2498, 0.0000],
          [0.0000, 0.2502]]],
        [[[0.2852, 0.0000],
          [0.0000, 0.2147]],
         [[0.2856, 0.0000],
          [0.0000, 0.2145]],
         [[0.2856, 0.0000],
          [0.0000, 0.2144]],
         [[0.2852, 0.0000],
          [0.0000, 0.2148]],
         [[0.3258, 0.0000],
          [0.0000, 0.1842]],
         [[0.2855, 0.0000],
          [0.0000, 0.2145]],
         [[0.2855, 0.0000],
          [0.0000, 0.2145]],
         [[0.2854, 0.0000],
          [0.0000, 0.2146]]],
        [[[0.2500, 0.0000],
          [0.0000, 0.2500]],
         [[0.2503, 0.0000],
          [0.0000, 0.2497]],
         [[0.2503, 0.0000],
          [0.0000, 0.2497]],
         [[0.2499, 0.0000],
          [0.0000, 0.2501]],
         [[0.2855, 0.0000],
          [0.0000, 0.2145]],
         [[0.2502, 0.0000],
          [0.0000, 0.2498]],
         [[0.2502, 0.0000],
          [0.0000, 0.2498]],
         [[0.2501, 0.0000],
          [0.0000, 0.2499]]],
        [[[0.2499, 0.0000],
          [0.0000, 0.2501]],
         [[0.2502, 0.0000],
          [0.0000, 0.2498]],
         [[0.2503, 0.0000],
          [0.0000, 0.2497]],
         [[0.2499, 0.0000],
          [0.0000, 0.2501]],
         [[0.2855, 0.0000],
          [0.0000, 0.2145]],
         [[0.2502, 0.0000],
          [0.0000, 0.2498]],
         [[0.2502, 0.0000],
          [0.0000, 0.2498]],
         [[0.2501, 0.0000],
          [0.0000, 0.2499]]],
        [[[0.2498, 0.0000],
          [0.0000, 0.2502]],
         [[0.2501, 0.0000],
          [0.0000, 0.2499]],
         [[0.2502, 0.0000],
          [0.0000, 0.2498]],
         [[0.2498, 0.0000],
          [0.0000, 0.2502]],
         [[0.2854, 0.0000],
          [0.0000, 0.2146]],
         [[0.2501, 0.0000],
          [0.0000, 0.2499]],
         [[0.2501, 0.0000],
          [0.0000, 0.2499]],
         [[0.2500, 0.0000],
          [0.0000, 0.2500]]]], device='cuda:0')
[1m([22mPdb[1m)
tensor([[[0.2497, 0.0000],
         [0.0000, 0.2503]],
        [[0.2500, 0.0000],
         [0.0000, 0.2500]],
        [[0.2500, 0.0000],
         [0.0000, 0.2500]],
        [[0.2497, 0.0000],
         [0.0000, 0.2503]],
        [[0.2852, 0.0000],
         [0.0000, 0.2147]],
        [[0.2500, 0.0000],
         [0.0000, 0.2500]],
        [[0.2499, 0.0000],
         [0.0000, 0.2501]],
        [[0.2498, 0.0000],
         [0.0000, 0.2502]]], device='cuda:0')
[1m([22mPdb[1m)
torch.Size([8, 8, 2, 2])
[1m([22mPdb[1m)
tensor([[0.2497, 0.0000],
        [0.0000, 0.2503]], device='cuda:0')
[1m([22mPdb[1m)
tensor([[1.0000e+00, 3.7632e-04, 1.1351e-06, 1.3255e-03, 5.6812e-06, 3.6682e-03,
         5.4700e-04, 2.8586e-04],
        [3.7632e-04, 1.0000e+00, 2.3851e-04, 3.4948e-02, 2.8149e-03, 3.5183e-03,
         3.0531e-02, 2.5446e-02],
        [1.1351e-06, 2.3851e-04, 1.0000e+00, 1.7984e-04, 6.5035e-06, 2.6214e-05,
         4.5288e-04, 2.5734e-04],
        [1.3255e-03, 3.4948e-02, 1.7984e-04, 1.0000e+00, 6.4190e-04, 3.0556e-03,
         2.8101e-02, 1.7378e-02],
        [5.6812e-06, 2.8149e-03, 6.5035e-06, 6.4190e-04, 1.0000e+00, 8.9313e-05,
         6.2324e-04, 4.1656e-04],
        [3.6682e-03, 3.5183e-03, 2.6214e-05, 3.0556e-03, 8.9313e-05, 1.0000e+00,
         1.5789e-02, 6.6578e-03],
        [5.4700e-04, 3.0531e-02, 4.5288e-04, 2.8101e-02, 6.2324e-04, 1.5789e-02,
         1.0000e+00, 6.0583e-02],
        [2.8586e-04, 2.5446e-02, 2.5734e-04, 1.7378e-02, 4.1656e-04, 6.6578e-03,
         6.0583e-02, 1.0000e+00]], device='cuda:0')
[1m([22mPdb[1m)
torch.Size([8, 8])
[1m([22mPdb[1m)
torch.Size([8, 104])
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(85)__call__()
-> total_yj = torch.einsum('ic,jc->ijc', q_y, k_yj)
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(86)__call__()
-> y_one_hot = F.one_hot(y, num_classes=num_classes).float()
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(88)__call__()
-> loss_mat = scaler * total_yy.sum(dim=(2,3))
[1m([22mPdb[1m)
1.0
[1m([22mPdb[1m)
tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5001, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.4999, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5001, 0.4999, 0.5100, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000]],
       device='cuda:0')
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(89)__call__()
-> loss_mat2 = scaler * total_yj.sum(-1)
[1m([22mPdb[1m)
tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5001, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.4999, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5001, 0.4999, 0.5100, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000]],
       device='cuda:0')
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py(90)__call__()
-> loss_mat3 = scaler * self.kernel_fun[op](y_one_hot, y_one_hot, bandwidth)
[1m([22mPdb[1m)
tensor([[0.4997, 0.4997, 0.4997, 0.5003, 0.4997, 0.4997, 0.4997, 0.4997],
        [0.5003, 0.5003, 0.5003, 0.4997, 0.5003, 0.5003, 0.5003, 0.5003],
        [0.5004, 0.5004, 0.5004, 0.4996, 0.5004, 0.5004, 0.5004, 0.5004],
        [0.4996, 0.4996, 0.4996, 0.5004, 0.4996, 0.4996, 0.4996, 0.4996],
        [0.5708, 0.5708, 0.5708, 0.4292, 0.5708, 0.5708, 0.5708, 0.5708],
        [0.5002, 0.5002, 0.5002, 0.4998, 0.5002, 0.5002, 0.5002, 0.5002],
        [0.5002, 0.5002, 0.5002, 0.4998, 0.5002, 0.5002, 0.5002, 0.5002],
        [0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000]],
       device='cuda:0')
[1m([22mPdb[1m)
Error executing job with overrides: ['experiment=classification_mixed', 'debug=default']
Traceback (most recent call last):
  File "/local/scratch/a/ko120/DM-Benchmark/train.py", line 44, in main
    return train(config)
  File "/local/scratch/a/ko120/DM-Benchmark/src/training_pipeline.py", line 90, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self._run_sanity_check()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1052, in _run_sanity_check
    val_loop.run()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/lightening_module.py", line 144, in validation_step
    loss, preds, logits, targets  = self.step(batch)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/lightening_module.py", line 101, in step
    loss = self.criterion(x, y ,logits)
  File "/local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py", line 129, in __call__
  File "/local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py", line 90, in __call__
    loss_mat = scaler * total_yy.sum(dim=(2,3))
  File "/local/scratch/a/ko120/DM-Benchmark/src/metrics/train_metrics.py", line 90, in __call__
    loss_mat = scaler * total_yy.sum(dim=(2,3))
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[?25h