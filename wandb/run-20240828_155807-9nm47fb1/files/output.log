[[36m2024-08-28 15:58:09,399[39m][[34msrc.training_pipeline[39m][[32mINFO[39m] - Starting training!
[[36m2024-08-28 15:58:09,438[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[[36m2024-08-28 15:58:09,440[39m][[34mpytorch_lightning.accelerators.cuda[39m][[32mINFO[39m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓
┃[1m    [22m┃[1m Name                        [22m┃[1m Type                                 [22m┃[1m Params [22m┃[1m Mode  [22m┃
┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩
│ 0  │ net                         │ LaftrNet                             │  8.2 K │ train │
│ 1  │ net.encoder                 │ MLP                                  │  4.9 K │ train │
│ 2  │ net.encoder.hiddens         │ ModuleList                           │  4.9 K │ train │
│ 3  │ net.encoder.hiddens.0       │ Linear                               │  3.3 K │ train │
│ 4  │ net.encoder.hiddens.1       │ Linear                               │  1.1 K │ train │
│ 5  │ net.encoder.hiddens.2       │ Linear                               │    528 │ train │
│ 6  │ net.classifier              │ MLP                                  │  1.7 K │ train │
│ 7  │ net.classifier.hiddens      │ ModuleList                           │  1.7 K │ train │
│ 8  │ net.classifier.hiddens.0    │ Linear                               │    544 │ train │
│ 9  │ net.classifier.hiddens.1    │ Linear                               │  1.1 K │ train │
│ 10 │ net.classifier.hiddens.2    │ Linear                               │     66 │ train │
│ 11 │ net.discriminator           │ MLP                                  │  1.6 K │ train │
│ 12 │ net.discriminator.hiddens   │ ModuleList                           │  1.6 K │ train │
│ 13 │ net.discriminator.hiddens.0 │ Linear                               │    544 │ train │
│ 14 │ net.discriminator.hiddens.1 │ Linear                               │  1.1 K │ train │
│ 15 │ net.discriminator.hiddens.2 │ Linear                               │     33 │ train │
│ 16 │ criterion                   │ CrossEntropyLoss                     │      0 │ train │
│ 17 │ CE                          │ CrossEntropyLoss                     │      0 │ train │
│ 18 │ l1_loss                     │ MeanAbsoluteError                    │      0 │ train │
│ 19 │ train_acc                   │ BinaryAccuracy                       │      0 │ train │
│ 20 │ val_acc                     │ BinaryAccuracy                       │      0 │ train │
│ 21 │ test_acc                    │ BinaryAccuracy                       │      0 │ train │
│ 22 │ train_ece                   │ MulticlassCalibrationError           │      0 │ train │
│ 23 │ val_ece                     │ MulticlassCalibrationError           │      0 │ train │
│ 24 │ test_ece                    │ MulticlassCalibrationError           │      0 │ train │
│ 25 │ train_entropy               │ ShannonEntropyError                  │      0 │ train │
│ 26 │ val_entropy                 │ ShannonEntropyError                  │      0 │ train │
│ 27 │ test_entropy                │ ShannonEntropyError                  │      0 │ train │
│ 28 │ test_kcal                   │ ClassificationKernelCalibrationError │      0 │ train │
│ 29 │ val_acc_best                │ MaxMetric                            │      0 │ train │
│ 30 │ val_ece_best                │ MinMetric                            │      0 │ train │
│ 31 │ val_entropy_best            │ MinMetric                            │      0 │ train │
└────┴─────────────────────────────┴──────────────────────────────────────┴────────┴───────┘
[1mTrainable params[22m: 8.2 K
[1mNon-trainable params[22m: 0
[1mTotal params[22m: 8.2 K
[1mTotal estimated model params size (MB)[22m: 0
[1mModules in train mode[22m: 32
[1mModules in eval mode[22m: 0
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may
be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which
may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
> /local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py(135)training_step()
-> A_hat = self.net.discriminator(Z)
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m0/329[39m [38m0:00:00 • -:--:--[39m [38m0.00it/s[39m [37mv_num: 7fb1 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331           
                                                                                     [37mval/acc_best: 0.875 val/ece_best: 0.331                                                                     
        [-1.3911e-03],
        [-4.6801e-04],
        [-6.4893e-04],
        [-5.5519e-04],
        [-1.6246e-03],
        [ 3.4496e-02],
        [ 8.2958e-02],
        [-4.5371e-04],
        [ 3.7971e-02],
        [-7.5292e-04],
        [-1.2852e-03],
        [ 6.3304e-02],
        [-4.5734e-03],
        [-9.8836e-04],
        [-1.6569e-05],
        [ 1.5129e-02],
        [-7.3440e-05],
        [ 2.9721e-02],
        [ 1.0918e-01],
        [-1.4181e-03],
        [-6.8345e-04],
        [-1.2866e-03],
        [-5.9548e-04],
        [-1.7949e-04],
        [-8.8336e-04],
        [-6.2632e-04],
        [-2.2637e-03],
        [-2.1251e-03],
        [-1.6527e-03],
        [-1.6448e-04],
        [-2.4916e-03],
        [ 2.5594e-02],
        [ 9.5753e-02],
        [-5.3646e-04],
        [ 2.6763e-02],
        [-3.4442e-03],
        [-1.0480e-03],
        [-1.2898e-03],
        [-1.2937e-03],
        [-8.0772e-04],
        [-2.1247e-04],
        [-2.4985e-03],
        [-1.3547e-03],
        [-1.3574e-03],
        [-1.2255e-03],
        [-1.8346e-03],
        [-3.3864e-04],
        [-5.8761e-04],
        [-5.8976e-04],
        [ 3.3666e-02],
        [-4.1999e-04],
        [ 1.2381e-01],
        [ 3.0155e-02],
        [-3.9022e-04],
        [-3.8245e-04],
        [-9.4079e-04],
        [ 1.2113e-01],
        [-2.3277e-03],
        [-1.6943e-03],
        [-8.9712e-04],
        [-1.4839e-03],
        [-1.1550e-03],
[37mEpoch 0/0 [39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m0/329[39m [38m0:00:00 • -:--:--[39m [38m0.00it/s[39m [37mv_num: 7fb1 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331           
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m0/329[39m [38m0:00:00 • -:--:--[39m [38m0.00it/s[39m [37mv_num: 7fb1 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331           
                                                                                     [37mval/acc_best: 0.875 val/ece_best: 0.331                                                                     
[1m([22mPdb[1m)
    self.advance(kwargs)/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 252, in advance
    batch_output = self.manual_optimization.run(kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py", line 94, in run
    self.advance(kwargs)/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py", line 114, in advance
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 115, in training_step
    Y, logits, A, preds, Z = self.step(batch)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 108, in step
    Z = self.net.encoder(X)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/components/models.py", line 78, in forward
    L = hidden(L)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
 (Triggered internally at ../torch/csrc/autograd/python_anomaly_mode.cpp:111.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [32, 16]], which is output 0 of AsStridedBackward0, is at
version 3; expected version 2 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere
later. Good luck!
> /local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py(138)training_step()
-> self.manual_backward(aud_loss)
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━[39m [37m0/329[39m [38m0:00:00 • -:--:--[39m [38m0.00it/s[39m [37mv_num: 7fb1 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331           
                                                                                     [37mval/acc_best: 0.875 val/ece_best: 0.331                                                                     
[?25h
                                                                                     [37mval/acc_best: 0.875 val/ece_best: 0.331                                                                     
Error executing job with overrides: ['experiment=classification_fair', 'debug=default']
Traceback (most recent call last):
  File "/local/scratch/a/ko120/DM-Benchmark/train.py", line 44, in main
    return train(config)
  File "/local/scratch/a/ko120/DM-Benchmark/src/training_pipeline.py", line 90, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 252, in advance
    batch_output = self.manual_optimization.run(kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py", line 94, in run
    self.advance(kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py", line 114, in advance
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 138, in training_step
    self.manual_backward(aud_loss)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 96, in trace_dispatch
    return self.dispatch_exception(frame, arg)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 176, in dispatch_exception
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.