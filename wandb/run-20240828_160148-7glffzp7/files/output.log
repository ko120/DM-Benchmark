[[36m2024-08-28 16:01:51,065[39m][[34msrc.training_pipeline[39m][[32mINFO[39m] - Starting training!
[[36m2024-08-28 16:01:51,095[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[[36m2024-08-28 16:01:51,097[39m][[34mpytorch_lightning.accelerators.cuda[39m][[32mINFO[39m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ[1m    [22m‚îÉ[1m Name                        [22m‚îÉ[1m Type                                 [22m‚îÉ[1m Params [22m‚îÉ[1m Mode  [22m‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ 0  ‚îÇ net                         ‚îÇ LaftrNet                             ‚îÇ  8.2 K ‚îÇ train ‚îÇ
‚îÇ 1  ‚îÇ net.encoder                 ‚îÇ MLP                                  ‚îÇ  4.9 K ‚îÇ train ‚îÇ
‚îÇ 2  ‚îÇ net.encoder.hiddens         ‚îÇ ModuleList                           ‚îÇ  4.9 K ‚îÇ train ‚îÇ
‚îÇ 3  ‚îÇ net.encoder.hiddens.0       ‚îÇ Linear                               ‚îÇ  3.3 K ‚îÇ train ‚îÇ
‚îÇ 4  ‚îÇ net.encoder.hiddens.1       ‚îÇ Linear                               ‚îÇ  1.1 K ‚îÇ train ‚îÇ
‚îÇ 5  ‚îÇ net.encoder.hiddens.2       ‚îÇ Linear                               ‚îÇ    528 ‚îÇ train ‚îÇ
‚îÇ 6  ‚îÇ net.classifier              ‚îÇ MLP                                  ‚îÇ  1.7 K ‚îÇ train ‚îÇ
‚îÇ 7  ‚îÇ net.classifier.hiddens      ‚îÇ ModuleList                           ‚îÇ  1.7 K ‚îÇ train ‚îÇ
‚îÇ 8  ‚îÇ net.classifier.hiddens.0    ‚îÇ Linear                               ‚îÇ    544 ‚îÇ train ‚îÇ
‚îÇ 9  ‚îÇ net.classifier.hiddens.1    ‚îÇ Linear                               ‚îÇ  1.1 K ‚îÇ train ‚îÇ
‚îÇ 10 ‚îÇ net.classifier.hiddens.2    ‚îÇ Linear                               ‚îÇ     66 ‚îÇ train ‚îÇ
‚îÇ 11 ‚îÇ net.discriminator           ‚îÇ MLP                                  ‚îÇ  1.6 K ‚îÇ train ‚îÇ
‚îÇ 12 ‚îÇ net.discriminator.hiddens   ‚îÇ ModuleList                           ‚îÇ  1.6 K ‚îÇ train ‚îÇ
‚îÇ 13 ‚îÇ net.discriminator.hiddens.0 ‚îÇ Linear                               ‚îÇ    544 ‚îÇ train ‚îÇ
‚îÇ 14 ‚îÇ net.discriminator.hiddens.1 ‚îÇ Linear                               ‚îÇ  1.1 K ‚îÇ train ‚îÇ
‚îÇ 15 ‚îÇ net.discriminator.hiddens.2 ‚îÇ Linear                               ‚îÇ     33 ‚îÇ train ‚îÇ
‚îÇ 16 ‚îÇ criterion                   ‚îÇ CrossEntropyLoss                     ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 17 ‚îÇ CE                          ‚îÇ CrossEntropyLoss                     ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 18 ‚îÇ l1_loss                     ‚îÇ MeanAbsoluteError                    ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 19 ‚îÇ train_acc                   ‚îÇ BinaryAccuracy                       ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 20 ‚îÇ val_acc                     ‚îÇ BinaryAccuracy                       ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 21 ‚îÇ test_acc                    ‚îÇ BinaryAccuracy                       ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 22 ‚îÇ train_ece                   ‚îÇ MulticlassCalibrationError           ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 23 ‚îÇ val_ece                     ‚îÇ MulticlassCalibrationError           ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 24 ‚îÇ test_ece                    ‚îÇ MulticlassCalibrationError           ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 25 ‚îÇ train_entropy               ‚îÇ ShannonEntropyError                  ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 26 ‚îÇ val_entropy                 ‚îÇ ShannonEntropyError                  ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 27 ‚îÇ test_entropy                ‚îÇ ShannonEntropyError                  ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 28 ‚îÇ test_kcal                   ‚îÇ ClassificationKernelCalibrationError ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 29 ‚îÇ val_acc_best                ‚îÇ MaxMetric                            ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 30 ‚îÇ val_ece_best                ‚îÇ MinMetric                            ‚îÇ      0 ‚îÇ train ‚îÇ
‚îÇ 31 ‚îÇ val_entropy_best            ‚îÇ MinMetric                            ‚îÇ      0 ‚îÇ train ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
[1mTrainable params[22m: 8.2 K
[1mNon-trainable params[22m: 0
[1mTotal params[22m: 8.2 K
[1mTotal estimated model params size (MB)[22m: 0
[1mModules in train mode[22m: 32
[1mModules in eval mode[22m: 0
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may
be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which
may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
> /local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py(135)training_step()
-> A_hat = self.net.discriminator(Z.detach())
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[39m [37m0/329[39m [38m0:00:00 ‚Ä¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: fzp7 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331           
                                                                                     [37mval/acc_best: 0.875 val/ece_best: 0.331                                                                     
-> A_hat_prob = torch.sigmoid(A_hat)
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py(137)training_step()
-> aud_loss = -0.01*self.l1_loss(A_hat_prob,A)
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[39m [37m0/329[39m [38m0:00:00 ‚Ä¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: fzp7 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331           
-> self.manual_backward(aud_loss)
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py(139)training_step()
-> torch.nn.utils.clip_grad_norm_(self.net.audit_params(), 5.0)
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[39m [37m0/329[39m [38m0:00:00 ‚Ä¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: fzp7 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331           
[1m([22mPdb[1m)
> /local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py(140)training_step()
-> optimizer_d.step()
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[39m [37m0/329[39m [38m0:00:00 ‚Ä¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: fzp7 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331           
-> optimizer_d.zero_grad()
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[39m [37m0/329[39m [38m0:00:00 ‚Ä¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: fzp7 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331           
                                                                                     [37mval/acc_best: 0.875 val/ece_best: 0.331                                                                     
[?25h
Error executing job with overrides: ['experiment=classification_fair', 'debug=default']
Traceback (most recent call last):
  File "/local/scratch/a/ko120/DM-Benchmark/train.py", line 44, in main
    return train(config)
  File "/local/scratch/a/ko120/DM-Benchmark/src/training_pipeline.py", line 90, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 252, in advance
    batch_output = self.manual_optimization.run(kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py", line 94, in run
    self.advance(kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py", line 114, in advance
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 141, in training_step
    optimizer_d.step()
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 141, in training_step
    optimizer_d.step()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.