[[36m2024-08-27 16:02:26,951[39m][[34msrc.training_pipeline[39m][[32mINFO[39m] - Starting training!
[[36m2024-08-27 16:02:26,991[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[[36m2024-08-27 16:02:26,993[39m][[34mpytorch_lightning.accelerators.cuda[39m][[32mINFO[39m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ[1m    [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type                                 [22mâ”ƒ[1m Params [22mâ”ƒ[1m Mode  [22mâ”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                         â”‚ LaftrNet                             â”‚  8.2 K â”‚ train â”‚
â”‚ 1  â”‚ net.encoder                 â”‚ MLP                                  â”‚  4.9 K â”‚ train â”‚
â”‚ 2  â”‚ net.encoder.hiddens         â”‚ ModuleList                           â”‚  4.9 K â”‚ train â”‚
â”‚ 3  â”‚ net.encoder.hiddens.0       â”‚ Linear                               â”‚  3.3 K â”‚ train â”‚
â”‚ 4  â”‚ net.encoder.hiddens.1       â”‚ Linear                               â”‚  1.1 K â”‚ train â”‚
â”‚ 5  â”‚ net.encoder.hiddens.2       â”‚ Linear                               â”‚    528 â”‚ train â”‚
â”‚ 6  â”‚ net.classifier              â”‚ MLP                                  â”‚  1.7 K â”‚ train â”‚
â”‚ 7  â”‚ net.classifier.hiddens      â”‚ ModuleList                           â”‚  1.7 K â”‚ train â”‚
â”‚ 8  â”‚ net.classifier.hiddens.0    â”‚ Linear                               â”‚    544 â”‚ train â”‚
â”‚ 9  â”‚ net.classifier.hiddens.1    â”‚ Linear                               â”‚  1.1 K â”‚ train â”‚
â”‚ 10 â”‚ net.classifier.hiddens.2    â”‚ Linear                               â”‚     66 â”‚ train â”‚
â”‚ 11 â”‚ net.discriminator           â”‚ MLP                                  â”‚  1.7 K â”‚ train â”‚
â”‚ 12 â”‚ net.discriminator.hiddens   â”‚ ModuleList                           â”‚  1.7 K â”‚ train â”‚
â”‚ 13 â”‚ net.discriminator.hiddens.0 â”‚ Linear                               â”‚    544 â”‚ train â”‚
â”‚ 14 â”‚ net.discriminator.hiddens.1 â”‚ Linear                               â”‚  1.1 K â”‚ train â”‚
â”‚ 15 â”‚ net.discriminator.hiddens.2 â”‚ Linear                               â”‚     66 â”‚ train â”‚
â”‚ 16 â”‚ criterion                   â”‚ CrossEntropyLoss                     â”‚      0 â”‚ train â”‚
â”‚ 17 â”‚ CE                          â”‚ CrossEntropyLoss                     â”‚      0 â”‚ train â”‚
â”‚ 18 â”‚ l1_loss                     â”‚ MeanAbsoluteError                    â”‚      0 â”‚ train â”‚
â”‚ 19 â”‚ train_acc                   â”‚ BinaryAccuracy                       â”‚      0 â”‚ train â”‚
â”‚ 20 â”‚ val_acc                     â”‚ BinaryAccuracy                       â”‚      0 â”‚ train â”‚
â”‚ 21 â”‚ test_acc                    â”‚ BinaryAccuracy                       â”‚      0 â”‚ train â”‚
â”‚ 22 â”‚ train_ece                   â”‚ MulticlassCalibrationError           â”‚      0 â”‚ train â”‚
â”‚ 23 â”‚ val_ece                     â”‚ MulticlassCalibrationError           â”‚      0 â”‚ train â”‚
â”‚ 24 â”‚ test_ece                    â”‚ MulticlassCalibrationError           â”‚      0 â”‚ train â”‚
â”‚ 25 â”‚ train_entropy               â”‚ ShannonEntropyError                  â”‚      0 â”‚ train â”‚
â”‚ 26 â”‚ val_entropy                 â”‚ ShannonEntropyError                  â”‚      0 â”‚ train â”‚
â”‚ 27 â”‚ test_entropy                â”‚ ShannonEntropyError                  â”‚      0 â”‚ train â”‚
â”‚ 28 â”‚ test_kcal                   â”‚ ClassificationKernelCalibrationError â”‚      0 â”‚ train â”‚
â”‚ 29 â”‚ val_acc_best                â”‚ MaxMetric                            â”‚      0 â”‚ train â”‚
â”‚ 30 â”‚ val_ece_best                â”‚ MinMetric                            â”‚      0 â”‚ train â”‚
â”‚ 31 â”‚ val_entropy_best            â”‚ MinMetric                            â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 8.2 K
[1mNon-trainable params[22m: 0
[1mTotal params[22m: 8.2 K
[1mTotal estimated model params size (MB)[22m: 0
[1mModules in train mode[22m: 32
[1mModules in eval mode[22m: 0
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers
which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers
which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
> /local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py(138)training_step()
-> A_hat_prob = A_hat_prob[ind]
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/329[39m [38m0:00:00 â€¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: l072 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331   
                                                                                     [37mval/acc_best: 0.875 val/ece_best: 0.331                                                             
        1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,
[37mEpoch 0/0 [39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/329[39m [38m0:00:00 â€¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: l072 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331   
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/329[39m [38m0:00:00 â€¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: l072 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331   
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141]], device='cuda:0', grad_fn=<IndexBackward0>)
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/329[39m [38m0:00:00 â€¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: l072 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331   
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4998, 0.5141],
        [0.4999, 0.5229],
        [0.4998, 0.5141],
        [0.4998, 0.5141]], device='cuda:0', grad_fn=<IndexBackward0>)
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/329[39m [38m0:00:00 â€¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: l072 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331   
                                                                                     [37mval/acc_best: 0.875 val/ece_best: 0.331                                                             
        [0.4999, 0.5312],
        [0.4996, 0.4996],
        [0.4999, 0.4996],
        [0.4999, 0.5118],
        [0.4999, 0.4999],
        [0.4996, 0.4999],
        [0.4999, 0.5222],
        [0.5015, 0.5029],
        [0.5268, 0.5170],
        [0.4998, 0.4999],
        [0.4998, 0.5115],
        [0.4995, 0.5370],
        [0.4996, 0.4997],
        [0.5164, 0.5094],
        [0.4997, 0.5000],
        [0.4996, 0.5233],
        [0.5130, 0.5159],
        [0.5761, 0.4989],
        [0.4998, 0.5004],
        [0.4995, 0.5048],
        [0.4998, 0.5082],
        [0.4998, 0.5141],
        [0.4999, 0.4999],
        [0.5479, 0.4995],
        [0.5265, 0.5193],
        [0.5017, 0.5392],
        [0.4997, 0.5093],
        [0.4997, 0.5221],
        [0.4999, 0.4997],
        [0.4998, 0.5105],
        [0.5004, 0.5137],
        [0.4999, 0.5000],
        [0.4998, 0.5358],
        [0.5191, 0.5085],
        [0.4997, 0.5073],
        [0.4995, 0.4999],
        [0.5081, 0.4998],
        [0.4996, 0.5212],
        [0.4999, 0.5373],
        [0.4996, 0.5269],
        [0.4999, 0.5026],
        [0.5088, 0.4998],
        [0.5002, 0.4996],
        [0.4998, 0.5113],
        [0.4998, 0.5214],
        [0.4997, 0.5009],
        [0.4997, 0.5234],
        [0.4997, 0.5000],
        [0.4998, 0.5020],
        [0.5658, 0.4997],
        [0.5029, 0.5066],
        [0.4998, 0.5033],
        [0.4998, 0.5159],
        [0.4995, 0.4969],
        [0.4998, 0.5090],
        [0.4997, 0.4999],
        [0.4997, 0.4998],
        [0.4996, 0.4999],
        [0.5000, 0.5097],
        [0.5573, 0.4999],
        [0.4999, 0.5468],
        [0.4992, 0.4999]], device='cuda:0', grad_fn=<SigmoidBackward0>)
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/329[39m [38m0:00:00 â€¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: l072 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331   
        1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,
        1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1], device='cuda:0')
[1m([22mPdb[1m)
[37mEpoch 0/0 [39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/329[39m [38m0:00:00 â€¢ -:--:--[39m [38m0.00it/s[39m [37mv_num: l072 val/loss: 6.323 val/ce_loss: 6.328 val/aud_loss: -0.005 val/acc: 0.875 val/ece: 0.331   
                                                                                     [37mval/acc_best: 0.875 val/ece_best: 0.331                                                             
        1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,
Error executing job with overrides: ['experiment=classification_fair', 'debug=default']
Traceback (most recent call last):
  File "/local/scratch/a/ko120/DM-Benchmark/train.py", line 44, in main
    return train(config)
  File "/local/scratch/a/ko120/DM-Benchmark/src/training_pipeline.py", line 90, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1025, in _run_stage
    self.fit_loop.run()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 205, in run
    self.advance()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py", line 363, in advance
    self.epoch_loop.run(self._data_fetcher)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 140, in run
    self.advance(data_fetcher)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py", line 252, in advance
    batch_output = self.manual_optimization.run(kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py", line 94, in run
    self.advance(kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py", line 114, in advance
    training_step_output = call._call_strategy_hook(trainer, "training_step", *kwargs.values())
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 390, in training_step
    return self.lightning_module.training_step(*args, **kwargs)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 138, in training_step
    A_hat_prob = A_hat_prob.unsqueeze(-1)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 138, in training_step
    A_hat_prob = A_hat_prob.unsqueeze(-1)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
        1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1,