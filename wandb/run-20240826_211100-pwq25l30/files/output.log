[[36m2024-08-26 21:11:03,101[39m][[34msrc.training_pipeline[39m][[32mINFO[39m] - Starting training!
[[36m2024-08-26 21:11:03,131[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - You are using a CUDA device ('NVIDIA RTX A5000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
[[36m2024-08-26 21:11:03,133[39m][[34mpytorch_lightning.accelerators.cuda[39m][[32mINFO[39m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ[1m    [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type                                 [22mâ”ƒ[1m Params [22mâ”ƒ[1m Mode  [22mâ”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ net                         â”‚ LaftrNet                             â”‚  8.2 K â”‚ train â”‚
â”‚ 1  â”‚ net.encoder                 â”‚ MLP                                  â”‚  4.9 K â”‚ train â”‚
â”‚ 2  â”‚ net.encoder.hiddens         â”‚ ModuleList                           â”‚  4.9 K â”‚ train â”‚
â”‚ 3  â”‚ net.encoder.hiddens.0       â”‚ Linear                               â”‚  3.3 K â”‚ train â”‚
â”‚ 4  â”‚ net.encoder.hiddens.1       â”‚ Linear                               â”‚  1.1 K â”‚ train â”‚
â”‚ 5  â”‚ net.encoder.hiddens.2       â”‚ Linear                               â”‚    528 â”‚ train â”‚
â”‚ 6  â”‚ net.classifier              â”‚ MLP                                  â”‚  1.7 K â”‚ train â”‚
â”‚ 7  â”‚ net.classifier.hiddens      â”‚ ModuleList                           â”‚  1.7 K â”‚ train â”‚
â”‚ 8  â”‚ net.classifier.hiddens.0    â”‚ Linear                               â”‚    544 â”‚ train â”‚
â”‚ 9  â”‚ net.classifier.hiddens.1    â”‚ Linear                               â”‚  1.1 K â”‚ train â”‚
â”‚ 10 â”‚ net.classifier.hiddens.2    â”‚ Linear                               â”‚     66 â”‚ train â”‚
â”‚ 11 â”‚ net.discriminator           â”‚ MLP                                  â”‚  1.7 K â”‚ train â”‚
â”‚ 12 â”‚ net.discriminator.hiddens   â”‚ ModuleList                           â”‚  1.7 K â”‚ train â”‚
â”‚ 13 â”‚ net.discriminator.hiddens.0 â”‚ Linear                               â”‚    544 â”‚ train â”‚
â”‚ 14 â”‚ net.discriminator.hiddens.1 â”‚ Linear                               â”‚  1.1 K â”‚ train â”‚
â”‚ 15 â”‚ net.discriminator.hiddens.2 â”‚ Linear                               â”‚     66 â”‚ train â”‚
â”‚ 16 â”‚ criterion                   â”‚ CrossEntropyLoss                     â”‚      0 â”‚ train â”‚
â”‚ 17 â”‚ CE                          â”‚ CrossEntropyLoss                     â”‚      0 â”‚ train â”‚
â”‚ 18 â”‚ l1_loss                     â”‚ MeanAbsoluteError                    â”‚      0 â”‚ train â”‚
â”‚ 19 â”‚ train_acc                   â”‚ BinaryAccuracy                       â”‚      0 â”‚ train â”‚
â”‚ 20 â”‚ val_acc                     â”‚ BinaryAccuracy                       â”‚      0 â”‚ train â”‚
â”‚ 21 â”‚ test_acc                    â”‚ BinaryAccuracy                       â”‚      0 â”‚ train â”‚
â”‚ 22 â”‚ train_ece                   â”‚ BinaryCalibrationError               â”‚      0 â”‚ train â”‚
â”‚ 23 â”‚ val_ece                     â”‚ BinaryCalibrationError               â”‚      0 â”‚ train â”‚
â”‚ 24 â”‚ test_ece                    â”‚ BinaryCalibrationError               â”‚      0 â”‚ train â”‚
â”‚ 25 â”‚ train_entropy               â”‚ ShannonEntropyError                  â”‚      0 â”‚ train â”‚
â”‚ 26 â”‚ val_entropy                 â”‚ ShannonEntropyError                  â”‚      0 â”‚ train â”‚
â”‚ 27 â”‚ test_entropy                â”‚ ShannonEntropyError                  â”‚      0 â”‚ train â”‚
â”‚ 28 â”‚ test_kcal                   â”‚ ClassificationKernelCalibrationError â”‚      0 â”‚ train â”‚
â”‚ 29 â”‚ val_acc_best                â”‚ MaxMetric                            â”‚      0 â”‚ train â”‚
â”‚ 30 â”‚ val_ece_best                â”‚ MinMetric                            â”‚      0 â”‚ train â”‚
â”‚ 31 â”‚ val_entropy_best            â”‚ MinMetric                            â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 8.2 K
[1mNon-trainable params[22m: 0
[1mTotal params[22m: 8.2 K
[1mTotal estimated model params size (MB)[22m: 0
[1mModules in train mode[22m: 32
[1mModules in eval mode[22m: 0
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a
bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.
> /local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py(116)step()
-> ce_loss = 10*self.CE(logit, Y)
[1m([22mPdb[1m)
[Parameter containing:
tensor([[-0.3374, -0.0584,  0.0987, -0.0559, -0.0479, -0.0417, -0.2891, -0.2789,
          0.3236, -0.2424,  0.2427, -0.2253,  0.2144,  0.1104, -0.3064, -0.1833],
        [-0.2892,  0.0125, -0.1443,  0.1817, -0.0291,  0.1647,  0.1972,  0.3332,
          0.2817, -0.2537, -0.0775, -0.0393,  0.2616,  0.2929,  0.2359, -0.0924],
        [-0.3528,  0.1863,  0.1129, -0.1872,  0.3060, -0.0628, -0.0274, -0.2328,
          0.0388,  0.0461, -0.0944, -0.2220, -0.0588,  0.0284,  0.2070,  0.2551],
        [-0.0884,  0.2487, -0.1657, -0.1344,  0.3477, -0.3348, -0.2991, -0.3533,
         -0.0309, -0.2725, -0.0623,  0.1095, -0.0389,  0.1751,  0.1523,  0.2708],
        [ 0.1274,  0.2660,  0.1211,  0.3464, -0.1428,  0.0174, -0.3473, -0.3467,
         -0.2333, -0.3132, -0.2451, -0.1241,  0.0511, -0.2423, -0.2068,  0.1082],
        [ 0.3258, -0.0596, -0.0474, -0.3221,  0.0127,  0.1048,  0.1056,  0.1871,
         -0.1394, -0.3006,  0.1137, -0.3387, -0.0427, -0.1037, -0.0557, -0.0997],
        [-0.3193,  0.2482,  0.0323, -0.1819,  0.1782,  0.0676,  0.1332,  0.2635,
          0.3088, -0.2423,  0.2557, -0.0860, -0.2730,  0.3100,  0.2013, -0.3340],
        [ 0.0954,  0.1339,  0.3214, -0.3263,  0.0025, -0.0935,  0.2493, -0.1946,
         -0.2256, -0.1819, -0.1764, -0.1393, -0.0860, -0.0281, -0.0126,  0.2863],
        [ 0.0237, -0.2903,  0.3522,  0.2596, -0.1338,  0.1327, -0.0661,  0.0695,
         -0.2535,  0.1172, -0.3486,  0.2112, -0.0785, -0.0200,  0.2513,  0.0615],
        [-0.3327, -0.0006,  0.3508, -0.1080, -0.1212,  0.3329,  0.2977,  0.1158,
          0.2098, -0.2683, -0.0460, -0.0755, -0.0418, -0.2920,  0.2012, -0.0386],
        [-0.0333, -0.0224,  0.2220,  0.3186,  0.0807, -0.2204, -0.2008,  0.3433,
          0.2569, -0.3365,  0.0990, -0.1138, -0.2263, -0.2392, -0.0781,  0.1732],
        [-0.2877, -0.0886, -0.2877,  0.3044, -0.3143, -0.2292,  0.2095, -0.0833,
          0.2717,  0.3381,  0.1345, -0.1254, -0.0666, -0.0297,  0.2282,  0.2418],
        [ 0.3139,  0.3294,  0.1356, -0.3331,  0.2246, -0.2449,  0.1664,  0.3066,
         -0.2784, -0.1618,  0.2377, -0.0802, -0.1461,  0.0749, -0.1598, -0.3302],
        [ 0.1270, -0.2346,  0.2659,  0.1019,  0.2067, -0.1471, -0.1987, -0.3134,
         -0.3116, -0.2374, -0.0761,  0.1287, -0.1018,  0.0963, -0.2180,  0.1837],
        [ 0.1119,  0.0548,  0.0188,  0.1989, -0.2097,  0.1559,  0.0556, -0.0175,
          0.0351, -0.2125, -0.1574,  0.0978, -0.2566, -0.3524,  0.0842,  0.0570],
        [ 0.2965, -0.2785,  0.0382,  0.2949, -0.2445,  0.1219, -0.2693, -0.2428,
          0.3166, -0.1846, -0.3384, -0.1692, -0.3403,  0.3196, -0.2992,  0.1082],
        [ 0.1664, -0.2524,  0.1183,  0.0032,  0.0545, -0.0059, -0.2153,  0.1577,
         -0.0160,  0.1101,  0.3322,  0.3023,  0.0965, -0.2781, -0.1227,  0.1671],
        [-0.0577, -0.0551, -0.2944, -0.1888,  0.2585,  0.3496,  0.0992, -0.0983,
         -0.2890, -0.3216, -0.1779,  0.3495, -0.3344,  0.1793,  0.1299, -0.1942],
        [-0.1623, -0.1551,  0.1302, -0.2022, -0.0786,  0.3524,  0.3161, -0.1755,
         -0.0727,  0.1742,  0.3244, -0.2782, -0.3491,  0.0430, -0.1210,  0.2865],
        [-0.0330,  0.2282,  0.0385,  0.1369, -0.3376,  0.3003, -0.0162,  0.1704,
          0.2842, -0.1272, -0.1090,  0.1114, -0.3465, -0.2650, -0.1780, -0.1082],
        [-0.3410, -0.1484, -0.2913,  0.2628,  0.1425, -0.3090,  0.2017,  0.3280,
         -0.0033, -0.2224,  0.1130,  0.3072, -0.3530,  0.0182, -0.1182, -0.2570],
        [-0.1011,  0.0349, -0.0174, -0.0609, -0.2553,  0.3086, -0.0431, -0.1187,
          0.0290, -0.1773, -0.2974, -0.3504,  0.3338,  0.2871,  0.2463, -0.2455],
        [-0.0087, -0.2648, -0.0835,  0.3108,  0.2019, -0.2378, -0.0147, -0.1778,
         -0.3000, -0.1051,  0.2524,  0.1197,  0.3140,  0.0506,  0.1942, -0.3118],
        [ 0.3089, -0.1440, -0.0675,  0.0510,  0.0068,  0.2558, -0.1611, -0.2637,
         -0.0951,  0.2803,  0.2584, -0.0710,  0.2973,  0.0296,  0.1228, -0.1919],
        [ 0.3425, -0.0536,  0.2335, -0.2668,  0.0436,  0.2014,  0.0655, -0.0881,
         -0.0048,  0.2729,  0.0555, -0.2807,  0.3294,  0.0073,  0.1404, -0.1465],
        [-0.2895,  0.1879,  0.1751, -0.1709, -0.0984, -0.3523, -0.2731,  0.0488,
          0.2505,  0.2655,  0.0943, -0.3165,  0.0359, -0.3066, -0.2626, -0.0108],
        [-0.0321, -0.1199,  0.2933,  0.0756, -0.3404, -0.1693, -0.2108,  0.1180,
          0.1638, -0.2585, -0.0333,  0.2245, -0.2888, -0.2442,  0.1454,  0.0656],
        [-0.2617, -0.2523, -0.2688,  0.2513,  0.2472, -0.1851, -0.0253, -0.2993,
         -0.1287, -0.3193,  0.1524, -0.1213,  0.2510, -0.1815, -0.1384, -0.0785],
        [-0.3406, -0.1528,  0.1803,  0.1945, -0.1015, -0.2345,  0.0578,  0.1797,
         -0.0325,  0.2003, -0.0199,  0.3227,  0.3332, -0.2527,  0.2246,  0.3281],
        [ 0.1942,  0.2339, -0.2115, -0.1234,  0.0366,  0.1699,  0.2071, -0.2481,
          0.0596, -0.0469, -0.0449, -0.2458,  0.3159,  0.1511, -0.2430,  0.1059],
        [ 0.1241,  0.3267,  0.0698, -0.2291,  0.1962, -0.0304,  0.1929,  0.0566,
          0.3474, -0.1985,  0.1482, -0.0729,  0.2793, -0.2591, -0.2380,  0.1466],
        [ 0.3183,  0.1044,  0.1467,  0.2448, -0.2405,  0.2166, -0.0783, -0.2823,
         -0.2228,  0.2471,  0.1720, -0.1626,  0.2067, -0.2274, -0.0285,  0.0816]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0649,  0.1182,  0.0797,  0.0531, -0.1205, -0.0947,  0.1783, -0.2263,
        -0.2075,  0.2207, -0.1804,  0.0410,  0.1657,  0.2053, -0.0732, -0.2058,
         0.1149, -0.2152,  0.0466,  0.0797, -0.0354, -0.0097, -0.1652, -0.1207,
        -0.2444, -0.1542, -0.2385,  0.0854,  0.1795,  0.0745,  0.1549,  0.1241],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1024, -0.1455,  0.2872,  ...,  0.1168, -0.2303, -0.0077],
        [ 0.1104, -0.0365, -0.0840,  ...,  0.0532,  0.2842, -0.1609],
        [ 0.1633,  0.2255,  0.2207,  ...,  0.1868,  0.2494,  0.2081],
        ...,
        [-0.0301,  0.2212, -0.2680,  ..., -0.2527,  0.2560,  0.2882],
        [ 0.2937, -0.2272,  0.1255,  ...,  0.2526, -0.0040,  0.1678],
        [ 0.2487,  0.0982,  0.0090,  ...,  0.1237, -0.2750,  0.1566]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0797, -0.0944, -0.0813, -0.1021, -0.1653,  0.0988,  0.0239,  0.1563,
         0.0952, -0.0087, -0.0617, -0.1129, -0.0897,  0.1466, -0.0953,  0.1351,
         0.0959,  0.1409,  0.0815,  0.1416,  0.1401, -0.1408,  0.0092, -0.0036,
        -0.0397,  0.0520,  0.0146,  0.1566,  0.0683,  0.0346,  0.0970,  0.1044],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 2.2951e-01,  1.8929e-01, -5.3785e-02, -1.1458e-01, -4.1587e-01,
          3.5269e-01, -3.4004e-01, -3.4210e-02,  5.4850e-02, -1.7661e-01,
          3.5175e-01, -1.6373e-02,  4.3140e-02, -1.3248e-01,  2.1502e-01,
         -1.2662e-01,  3.4742e-01, -2.9336e-01, -1.2785e-02,  1.6572e-01,
          1.8788e-01, -3.3278e-01,  2.8710e-01, -1.2485e-01,  3.1416e-01,
         -3.3129e-01, -3.6967e-01,  1.7762e-01,  3.9236e-01,  4.0626e-01,
          1.5428e-01,  6.0269e-02],
        [ 3.7669e-01,  1.0868e-01,  4.1244e-01,  3.9399e-01, -2.5087e-01,
          1.6551e-04, -4.0910e-02,  2.1836e-01, -7.9640e-02, -6.4267e-02,
         -3.9455e-01, -3.7788e-01, -2.2525e-01, -1.3421e-01, -1.1552e-01,
          8.6497e-02, -1.1690e-01, -2.6817e-01,  3.9310e-01, -2.8705e-01,
         -2.3950e-01, -9.2089e-02,  1.2859e-01,  3.4225e-02, -3.3859e-01,
         -6.7086e-02, -2.1410e-01,  1.9508e-01,  5.9379e-02,  3.0449e-01,
         -2.7046e-01,  1.1939e-02]], device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.1615, -0.0347], device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1333,  0.1923,  0.1217,  ...,  0.0943, -0.1127, -0.0274],
        [ 0.0147, -0.0367,  0.1484,  ...,  0.0777,  0.1673, -0.1327],
        [ 0.1588, -0.1639,  0.2095,  ...,  0.1269,  0.1054, -0.1256],
        ...,
        [ 0.0620, -0.0914, -0.1160,  ...,  0.0465,  0.1815, -0.0231],
        [-0.0470,  0.0618,  0.1114,  ...,  0.0787, -0.0264, -0.0890],
        [ 0.0425,  0.0045,  0.1776,  ...,  0.0657,  0.0205,  0.2081]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.0518,  0.0213,  0.0199,  0.0165, -0.0365,  0.0020,  0.0579, -0.0203,
        -0.0098,  0.0085, -0.0780, -0.0608, -0.0396,  0.0681,  0.0871,  0.0725,
         0.0061,  0.0612, -0.0049,  0.0521, -0.0336,  0.0261,  0.0787,  0.0425,
         0.0541,  0.0296, -0.0436, -0.0542, -0.0533, -0.0833,  0.0096,  0.0095],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[ 0.1142,  0.2787, -0.2446,  ..., -0.0078, -0.0832, -0.2367],
        [ 0.1042, -0.1911, -0.2832,  ...,  0.0123,  0.2532, -0.0083],
        [ 0.0321, -0.2970, -0.2218,  ..., -0.0446, -0.2792,  0.2375],
        ...,
        [-0.0694, -0.0851, -0.2690,  ..., -0.2270,  0.2919, -0.2464],
        [-0.0847, -0.0964,  0.1292,  ...,  0.2244,  0.2477, -0.1199],
        [-0.2216, -0.2602,  0.0623,  ..., -0.1511,  0.1395,  0.1127]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([-0.1560, -0.0196,  0.0433,  0.0841,  0.0618, -0.1671,  0.1735,  0.0037,
         0.0965,  0.0319,  0.1504,  0.0237, -0.0761,  0.1319,  0.0173,  0.1504,
        -0.1491,  0.1348, -0.0531,  0.1400, -0.1541,  0.0703,  0.1431,  0.0422,
        -0.0313,  0.1416, -0.0666, -0.0634,  0.1022,  0.1417, -0.1006, -0.1734],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([[-0.1731,  0.1464,  0.1057, -0.0570, -0.0600, -0.1242, -0.1302, -0.3022,
          0.1505,  0.0255,  0.0060,  0.0966, -0.3016, -0.0288, -0.2774, -0.2251,
          0.0952, -0.2391, -0.0758,  0.3200,  0.2549, -0.2341,  0.2943, -0.2682,
          0.1816,  0.3304, -0.0181, -0.3105,  0.0790,  0.1762,  0.0940, -0.1371],
        [-0.2385, -0.1086, -0.2625,  0.0552,  0.1039, -0.3205,  0.3345,  0.3066,
          0.1439, -0.0605,  0.2547, -0.2738, -0.2327,  0.1759,  0.3385,  0.0937,
         -0.0791,  0.2992, -0.0779, -0.0527,  0.0326, -0.1602, -0.3410,  0.2860,
          0.2113,  0.1585,  0.3342, -0.3236, -0.1925,  0.2021,  0.0378, -0.2931],
        [-0.2991, -0.2512, -0.1674, -0.2369,  0.0073,  0.2842,  0.0385,  0.0108,
          0.1924,  0.3019, -0.2481,  0.1166, -0.2396, -0.2035,  0.3381, -0.2587,
          0.0014,  0.0259, -0.1723,  0.3006, -0.0770, -0.0828,  0.3113, -0.1243,
         -0.0242,  0.1665,  0.2144, -0.2218, -0.2366,  0.1202,  0.1556, -0.2139],
        [ 0.2998,  0.3454, -0.0006,  0.2892, -0.0893,  0.2671,  0.0130,  0.2545,
          0.2808, -0.2671,  0.2977, -0.1230, -0.3254,  0.2361,  0.2432,  0.3355,
         -0.1436, -0.2634,  0.0036, -0.1766, -0.2265,  0.0493,  0.0842,  0.1899,
         -0.3450, -0.2061,  0.2685,  0.3429, -0.3476, -0.0348, -0.1083, -0.2773],
        [-0.1120, -0.0303,  0.3145,  0.2084,  0.1315,  0.3095,  0.1500, -0.0061,
         -0.2707, -0.1420, -0.1904, -0.0729, -0.2136,  0.1412,  0.1510, -0.2693,
          0.1503,  0.0286, -0.1363,  0.2938,  0.1568, -0.1523, -0.1379, -0.0742,
         -0.0029,  0.2223, -0.2395,  0.1054, -0.2964,  0.2117,  0.0927,  0.1307],
        [ 0.0742,  0.0211,  0.1896,  0.0706,  0.1547, -0.2389,  0.3108,  0.2250,
          0.0843, -0.0864, -0.3265,  0.0889,  0.1236,  0.2199,  0.3422,  0.1958,
          0.3464,  0.1772,  0.3491,  0.0263,  0.0743, -0.3224,  0.0589,  0.2056,
          0.1678, -0.0952,  0.0518,  0.2174, -0.0964,  0.2645, -0.0493, -0.2380],
        [-0.1030, -0.0677, -0.1770, -0.1637, -0.1803, -0.0511, -0.0200, -0.1549,
         -0.1841,  0.0066, -0.2554,  0.3003, -0.2774, -0.0170,  0.1224, -0.2889,
          0.1811,  0.0644, -0.2354,  0.3426, -0.0077, -0.1636,  0.0539,  0.1233,
         -0.1315, -0.1190,  0.0036, -0.0946, -0.2029, -0.0128, -0.2339, -0.0041],
        [ 0.3059, -0.1229,  0.1569, -0.0210, -0.2724,  0.0480,  0.1598, -0.0280,
          0.2163,  0.1665,  0.0620, -0.2599, -0.3069, -0.1185, -0.1865, -0.1058,
          0.1137,  0.3131, -0.2362,  0.1430, -0.1905, -0.2453, -0.2509,  0.2332,
         -0.0374,  0.0168,  0.2483,  0.0566,  0.1393,  0.3039,  0.3343, -0.1182],
        [ 0.0871,  0.2220, -0.3473,  0.0716, -0.2902,  0.0616,  0.2084,  0.0056,
         -0.2171, -0.0898,  0.2944,  0.3128, -0.2090, -0.1400,  0.3477, -0.1772,
          0.3201,  0.1113,  0.1907, -0.0932, -0.3214, -0.1175, -0.1307, -0.3200,
          0.0117, -0.3501,  0.0229, -0.1440,  0.1644,  0.1834, -0.0601, -0.0440],
        [ 0.2044,  0.2306,  0.3057,  0.0097, -0.2813,  0.2407, -0.0642, -0.3380,
          0.0443, -0.2709,  0.0698,  0.0972, -0.1764, -0.0952, -0.1440, -0.1400,
         -0.2152,  0.0612, -0.0018, -0.3368, -0.1739,  0.2420,  0.0686,  0.2435,
          0.0267, -0.3032, -0.2718,  0.0017, -0.1060,  0.2077,  0.2431,  0.1164],
        [ 0.3258,  0.1314,  0.2503,  0.2813, -0.1087,  0.0165, -0.2499,  0.3226,
         -0.0731,  0.2424,  0.0841,  0.2830, -0.2299,  0.0756, -0.2916,  0.1163,
          0.2763,  0.0881,  0.0574, -0.2993,  0.2868, -0.2770,  0.2369, -0.3035,
         -0.2879, -0.1365, -0.2440,  0.1031,  0.1867, -0.0509, -0.3359, -0.2588],
        [ 0.0193,  0.1675, -0.0098, -0.3429,  0.1518,  0.0971,  0.0180,  0.2485,
          0.3143,  0.1289,  0.2903,  0.2781,  0.2048,  0.0330,  0.0860,  0.2009,
          0.2243,  0.0149,  0.0261, -0.1489,  0.1427, -0.0116,  0.0359, -0.0423,
          0.0064,  0.0814,  0.2091, -0.2936, -0.1098, -0.1852,  0.2453, -0.2810],
        [-0.2453,  0.2331,  0.2655, -0.1148,  0.2392,  0.1857, -0.0825, -0.3270,
          0.0435,  0.3112,  0.0014, -0.1911,  0.2780,  0.2678, -0.2885, -0.2522,
          0.0985, -0.2509, -0.0319, -0.3130, -0.3108, -0.1944,  0.1669, -0.2748,
         -0.1013, -0.1641, -0.1028, -0.2588,  0.1883,  0.2097,  0.2788,  0.3206],
        [ 0.0626,  0.0540, -0.3414, -0.0558,  0.0746, -0.3328, -0.0939, -0.3196,
         -0.0134, -0.3443, -0.1901,  0.1781, -0.0217,  0.0115,  0.0336, -0.2429,
         -0.0178,  0.2238,  0.0910, -0.1166, -0.2179,  0.3355, -0.2775, -0.0633,
          0.3244, -0.2846,  0.1582,  0.2400,  0.1060,  0.1158, -0.1943,  0.1262],
        [ 0.0075,  0.1459,  0.0437,  0.3255,  0.2852, -0.1846,  0.3445, -0.3343,
         -0.2668, -0.1014, -0.3322, -0.2520, -0.1145, -0.2476,  0.2380, -0.3111,
         -0.3238,  0.2282,  0.1505,  0.2325,  0.1792, -0.2593, -0.0672,  0.0100,
         -0.1936, -0.0498, -0.2023,  0.1651, -0.0556, -0.2438,  0.0562,  0.2016],
        [-0.1594, -0.1460,  0.0220, -0.3236, -0.1244, -0.0241,  0.3353,  0.0909,
         -0.2815, -0.0835,  0.1321,  0.1048,  0.2565, -0.3032,  0.0646,  0.1391,
         -0.1970, -0.2750, -0.1922, -0.1731,  0.2553,  0.2395, -0.2843,  0.1141,
          0.0051, -0.0818, -0.2122,  0.3016, -0.3394,  0.0328, -0.0880,  0.1659]],
       device='cuda:0', requires_grad=True), Parameter containing:
tensor([ 0.0170,  0.0250, -0.0627,  0.0002, -0.1593, -0.1636,  0.1104, -0.0230,
         0.1449,  0.1348,  0.1733, -0.1199, -0.1417,  0.1218,  0.1663,  0.1400],
       device='cuda:0', requires_grad=True)]
[1m([22mPdb[1m)
/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /local/scratch/a/ko120/DM-Benchmark/checkpoints exists and is not empty.
tensor([[ 2.2465e-01,  1.0900e-02],
        [ 2.2383e-01, -1.2168e-03],
        [ 2.1471e-01, -1.8974e-03],
        [ 2.1341e-01, -6.6544e-04],
        [ 1.2311e-01, -1.4957e-03],
        [ 1.8101e-01, -1.3051e-04],
        [ 3.1550e-01, -4.2535e-04],
        [ 1.3490e-01, -9.5630e-04]], device='cuda:0')
[1m([22mPdb[1m)
False
[1m([22mPdb[1m)
False
[1m([22mPdb[1m)
[1m([22mPdb[1m)
False
[1m([22mPdb[1m)
[?25h
Error executing job with overrides: ['experiment=classification_fair', 'debug=default']
Traceback (most recent call last):
  File "/local/scratch/a/ko120/DM-Benchmark/train.py", line 49, in <module>
    main()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/hydra/main.py", line 90, in decorated_main
    _run_hydra(
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/hydra/_internal/utils.py", line 389, in _run_hydra
    _run_app(
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/hydra/_internal/utils.py", line 452, in _run_app
    run_and_report(
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/hydra/_internal/utils.py", line 216, in run_and_report
    raise ex
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/hydra/_internal/utils.py", line 213, in run_and_report
    return func()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/hydra/_internal/utils.py", line 453, in <lambda>
    lambda: hydra.run(
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/local/scratch/a/ko120/DM-Benchmark/train.py", line 44, in main
    return train(config)
  File "/local/scratch/a/ko120/DM-Benchmark/src/training_pipeline.py", line 90, in train
    trainer.fit(model=model, datamodule=datamodule)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 538, in fit
    call._call_and_handle_interrupt(
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 574, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1023, in _run_stage
    self._run_sanity_check()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py", line 1052, in _run_sanity_check
    val_loop.run()
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 183, in validation_step
    total_loss, ce_loss, aud_loss, Y, logits, A, preds = self.step(batch)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 116, in step
    ce_loss = 10*self.CE(logit, Y)
  File "/local/scratch/a/ko120/DM-Benchmark/src/models/fair_lightening_module.py", line 116, in step
    ce_loss = 10*self.CE(logit, Y)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/local/scratch/a/ko120/miniconda3/envs/dm_real/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit