{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9GwMV-5GRTQ"
   },
   "source": [
    "# Metrics\n",
    "It is common practice in Lightening to inherent from\n",
    " torchmetrics for computation efficiency and competitability with Lightening (https://lightning.ai/docs/torchmetrics/stable/pages/implement.html#implement)\n",
    "\n",
    " TODO: Add metrics for other tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rJf5vaBpDqL3"
   },
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics import Metric\n",
    "from torchmetrics import MaxMetric, MinMetric\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "from torchmetrics.classification.calibration_error import CalibrationError\n",
    "\n",
    "from typing import Any, List, Literal, Optional, Dict, Callable\n",
    "\n",
    "\n",
    "# Metrics\n",
    "class ShannonEntropyError(Metric):\n",
    "    def __init__(self, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "\n",
    "        self.add_state(\"entropy_total\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"count\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, logits: torch.Tensor, is_dist=False):\n",
    "        p = logits if is_dist else F.softmax(logits, dim=-1)\n",
    "\n",
    "        self.entropy_total += torch.sum(- p * torch.log(p))\n",
    "        self.count += logits.shape[0]\n",
    "\n",
    "    def compute(self):\n",
    "        return self.entropy_total.float() / self.count.float()\n",
    "\n",
    "class ClassificationKernelCalibrationError(Metric):\n",
    "    def __init__(self, dist_sync_on_step=False, **kwargs):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "\n",
    "        self.add_state(\"kcal_total\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"count\", default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.kcal_func = ClassificationKernelLoss(**kwargs)\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor, inputs: torch.Tensor, verbose=False):\n",
    "        kcal = self.kcal_func(inputs, target, preds, verbose=verbose)\n",
    "\n",
    "        self.kcal_total += kcal\n",
    "        self.count += 1\n",
    "\n",
    "    def compute(self):\n",
    "        return self.kcal_total.float() / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgkpTLCxLX0W"
   },
   "source": [
    "# Loss\n",
    "\n",
    "TODO: add loss for other tasks and modify ClassificationMixedLoss to adopt DM losses to CE loss with initializing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TZ4LN6txLa4O"
   },
   "outputs": [],
   "source": [
    "# Kernels Utils\n",
    "\n",
    "def rbf_kernel(u: torch.Tensor, v: torch.Tensor, bandwidth=1):\n",
    "    diff_norm_mat = torch.norm(u.unsqueeze(1) - v, dim=2).square()\n",
    "    return torch.exp(- diff_norm_mat / bandwidth)\n",
    "\n",
    "def quadrant_partition_kernel(u: torch.Tensor, v: torch.Tensor):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "def norm_partition_kernel(u: torch.Tensor, v: torch.Tensor):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def tanh_kernel(u: torch.Tensor, v: torch.Tensor, bandwidth=1):\n",
    "    out = torch.tanh(v) * torch.tanh(u).unsqueeze(1) # N x N x 1 x num_samples\n",
    "    return out.squeeze(2)\n",
    "kernel_funs = {\"rbf\": rbf_kernel,\n",
    "               \"partition_quadrant\": quadrant_partition_kernel,\n",
    "               \"partition_norm\": norm_partition_kernel,\n",
    "               \"tanh\": tanh_kernel}\n",
    "\n",
    "VALID_OPERANDS = ['x', 'y', 'p', 'coords']\n",
    "\n",
    "def mean_no_diag(A):\n",
    "    assert A.dim() == 2 and A.shape[0] == A.shape[1]\n",
    "    n = A.shape[0]\n",
    "    A = A - torch.eye(n).to(A.device) * A.diag()\n",
    "    return A.sum() / (n * (n - 1))\n",
    "\n",
    "\n",
    "# Loss\n",
    "class ClassificationKernelLoss:\n",
    "    \"\"\"\n",
    "        MMD loss function for classification tasks.\n",
    "        Allows for distribution matching by specifying operands and kernel functions.\n",
    "        `scalers` and `bandwidths` are the parameters of the kernel functions.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 operands: Dict[str, str] = {'x': \"rbf\", 'y': \"rbf\"},\n",
    "                 scalers: Optional[Dict] = None,\n",
    "                 bandwidths: Optional[Dict] = {'x': 0.01, 'y': 1.0}):\n",
    "\n",
    "        assert all([op in VALID_OPERANDS for op in operands.keys()])\n",
    "\n",
    "        if scalers is None:\n",
    "            scalers = {op: 1. for op in operands.keys()}\n",
    "        else:\n",
    "            assert all(op in scalers for op in operands.keys())\n",
    "\n",
    "        self.kernel_fun = {op: kernel_funs[kernel] for op, kernel in operands.items()}\n",
    "        self.operands = list(operands.keys())\n",
    "        self.scalers = scalers\n",
    "        self.bandwidths = bandwidths\n",
    "\n",
    "    def __call__(self, x, y, logits, verbose=False):\n",
    "        kernel_out = None\n",
    "        loss_mats = [None for i in range(3)]\n",
    "\n",
    "        for op in self.operands:\n",
    "            scaler = self.scalers[op]\n",
    "            bandwidth = self.bandwidths[op]\n",
    "            if op == 'x':\n",
    "                # This is only true for tabular data. For example, multi-channel images will have 4D batches for x.\n",
    "                assert x.dim() == 2\n",
    "                loss_mat = loss_mat2 = loss_mat3 = scaler * self.kernel_fun[op](x, x, bandwidth)\n",
    "            elif op == 'y':\n",
    "                # Computes MMD loss for classification (See Section 4.1 of paper)\n",
    "                num_classes = logits.shape[-1]\n",
    "                y_all = torch.eye(num_classes).to(logits.device)\n",
    "                k_yy = self.kernel_fun[op](y_all, y_all, bandwidth)\n",
    "                q_y = F.softmax(logits, dim=-1)\n",
    "                q_yy = torch.einsum('ic,jd->ijcd', q_y, q_y)\n",
    "                total_yy = q_yy * k_yy.unsqueeze(0)\n",
    "\n",
    "                k_yj = k_yy[:,y].T\n",
    "                total_yj = torch.einsum('ic,jc->ijc', q_y, k_yj)\n",
    "                y_one_hot = F.one_hot(y, num_classes=num_classes).float()\n",
    "\n",
    "                loss_mat = scaler * total_yy.sum(dim=(2,3))\n",
    "                loss_mat2 = scaler * total_yj.sum(-1)\n",
    "                loss_mat3 = scaler * self.kernel_fun[op](y_one_hot, y_one_hot, bandwidth)\n",
    "            else:\n",
    "                assert False, f\"When running classification, operands must be x and y. Got operand {op} instead.\"\n",
    "\n",
    "            for i, value in enumerate([loss_mat, loss_mat2, loss_mat3]):\n",
    "                if loss_mats[i] is None:\n",
    "                    loss_mats[i] = value\n",
    "                else:\n",
    "                    loss_mats[i] =  loss_mats[i] * value\n",
    "\n",
    "        kernel_out = mean_no_diag(loss_mats[0]) - 2 * mean_no_diag(loss_mats[1]) + mean_no_diag(loss_mats[2])\n",
    "\n",
    "        return kernel_out\n",
    "\n",
    "class ClassificationCELoss:\n",
    "    \"\"\"\n",
    "        Cross-entropy loss for classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.loss = torch.nn.CrossEntropyLoss(**kwargs)\n",
    "\n",
    "    def __call__(self, x, y, logits):\n",
    "        return self.loss(logits, y)\n",
    "\n",
    "class ClassificationMixedLoss:\n",
    "    \"\"\"\n",
    "        Mixed loss function (MMD + NLL) for classification.\n",
    "        `loss_scalers` determines the mixture weight between MMD and NLL.\n",
    "    \"\"\"\n",
    "    def __init__(self, loss_scalers: Optional[Dict] = None, **kwargs):\n",
    "        if loss_scalers is None:\n",
    "            loss_scalers = {\"nll\": .01, \"mmd\": 1}\n",
    "        else:\n",
    "            assert set(loss_scalers.keys()) == {\"nll\", \"mmd\"}\n",
    "        self.loss_scalers = loss_scalers\n",
    "        self.nll = torch.nn.CrossEntropyLoss()\n",
    "        self.mmd = ClassificationKernelLoss(**kwargs)\n",
    "\n",
    "    def __call__(self, x, y, logits):\n",
    "        return self.loss_scalers[\"nll\"] * self.nll(logits, y) + self.loss_scalers[\"mmd\"] * self.mmd(x, y, logits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zaao277ULPqF"
   },
   "source": [
    "# Model\n",
    "This model's input size and output size will be determined by dataset which can be obtained from datamodule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kbZCiM1qDqL5"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "# Model\n",
    "class SimpleDenseNet(nn.Module):\n",
    "    \"\"\"\n",
    "        Neural network model for classificaiton.\n",
    "        Forward() call returns logits.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 784,\n",
    "        lin1_size: int = 256,\n",
    "        lin2_size: int = 256,\n",
    "        lin3_size: int = 256,\n",
    "        output_size: int = 10,\n",
    "        use_batchnorm: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if use_batchnorm:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(input_size, lin1_size),\n",
    "                nn.BatchNorm1d(lin1_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(lin1_size, lin2_size),\n",
    "                nn.BatchNorm1d(lin2_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(lin2_size, lin3_size),\n",
    "                nn.BatchNorm1d(lin3_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(lin3_size, output_size),\n",
    "            )\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(input_size, lin1_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(lin1_size, lin2_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(lin2_size, lin3_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(lin3_size, output_size),\n",
    "            )\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6v91zj4NisA"
   },
   "source": [
    "# Lightening Model\n",
    "\n",
    "TODO:add metrics on line 44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mMKlkGh0Ngpg"
   },
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import LightningModule\n",
    "from torchmetrics import MaxMetric, MinMetric\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "from torchmetrics.classification.calibration_error import CalibrationError\n",
    "import pdb\n",
    "from typing import Any, List, Literal, Optional, Dict, Callable\n",
    "# Core NN Module\n",
    "class ClassificationLitModule(LightningModule):\n",
    "    \"\"\" LightningModule for Classification tasks.\n",
    "\n",
    "    A LightningModule organizes your PyTorch code into 5 sections:\n",
    "        - Computations (init).\n",
    "        - Train loop (training_step)\n",
    "        - Validation loop (validation_step)\n",
    "        - Test loop (test_step)\n",
    "        - Optimizers (configure_optimizers)\n",
    "\n",
    "    Read the docs:\n",
    "        https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        net: torch.nn.Module,\n",
    "        criterion: Callable,\n",
    "        calibrator: Callable = None,\n",
    "        lr: float = 0.001,\n",
    "        weight_decay: float = 0.0005,\n",
    "        kcal_kwargs = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        # it also ensures init params will be stored in ckpt\n",
    "        self.save_hyperparameters(logger=False, ignore=['net'])  # this is needed for efficiency\n",
    "        self.net = net\n",
    "\n",
    "        # loss function\n",
    "        # self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.criterion = criterion\n",
    "        self.calibrator = calibrator\n",
    "        task = 'binary' if net.output_size == 2 else 'multiclass'\n",
    "\n",
    "        # use separate metric instance for train, val and test step\n",
    "        # to ensure a proper reduction over the epoch\n",
    "        self.train_acc = Accuracy(task= task)\n",
    "        self.val_acc = Accuracy(task= task)\n",
    "        self.test_acc = Accuracy(task= task)\n",
    "\n",
    "        # Initialize metrics\n",
    "        assert net.output_size >= 2, f\"Must have >=2 classes for classification task. Model only has {net.output_size} classes.\"\n",
    "        ece_kwargs = {\"task\": 'multiclass', \"n_bins\": 20, \"norm\": 'l1', \"num_classes\": net.output_size} # We are always using Multiclass ECE since we are considering binary case as multiclass by 0 as class1 and 1 as class 2\n",
    "        self.train_ece = CalibrationError(**ece_kwargs)\n",
    "        self.val_ece = CalibrationError(**ece_kwargs)\n",
    "        self.test_ece = CalibrationError(**ece_kwargs)\n",
    "\n",
    "        self.train_entropy = ShannonEntropyError()\n",
    "        self.val_entropy = ShannonEntropyError()\n",
    "        self.test_entropy = ShannonEntropyError()\n",
    "\n",
    "        if kcal_kwargs is None:\n",
    "            kcal_kwargs = {}\n",
    "        self.test_kcal = ClassificationKernelCalibrationError(**kcal_kwargs)\n",
    "\n",
    "        # For logging best validation metrics\n",
    "        self.val_acc_best = MaxMetric()\n",
    "        self.val_ece_best = MinMetric()\n",
    "        self.val_entropy_best = MinMetric()\n",
    "\n",
    "        # Additional metrics for post-hoc calibration\n",
    "        if self.calibrator:\n",
    "            self.test_calibrated_acc = Accuracy(task= task)\n",
    "            self.test_calibrated_ece = CalibrationError(**ece_kwargs)\n",
    "            self.test_calibrated_entropy = ShannonEntropyError()\n",
    "            self.test_calibrated_kcal = ClassificationKernelCalibrationError(**kcal_kwargs)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.net(x)\n",
    "\n",
    "    def on_train_start(self):\n",
    "        # by default lightning executes validation step sanity checks before training starts,\n",
    "        # so we need to make sure val_acc_best doesn't store accuracy from these checks\n",
    "        self.val_acc_best.reset()\n",
    "        self.val_ece_best.reset()\n",
    "\n",
    "    def step(self, batch: Any):\n",
    "        x, y = batch\n",
    "        y = y.squeeze(-1)\n",
    "        logits = self.forward(x)\n",
    "        loss = self.criterion(x, y ,logits)\n",
    "        pdb.set_trace()\n",
    "        # Question should we disable taking gradient for preds and probs since it is only being used on computing metrics?\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "        return loss, preds, logits, y, probs\n",
    "\n",
    "    def training_step(self, batch: Any, batch_idx: int):\n",
    "        loss, preds, logits, targets, probs = self.step(batch)\n",
    "\n",
    "        # log train metrics\n",
    "\n",
    "        acc = self.train_acc(preds, targets)\n",
    "        ece = self.train_ece(probs, targets)\n",
    "        entropy = self.train_entropy(logits)\n",
    "\n",
    "        self.log(\"train/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train/ece\", ece, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train/entropy\", entropy, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # we can return here dict with any tensors\n",
    "        # and then read it in some callback or in `training_epoch_end()` below\n",
    "        # remember to always return loss from `training_step()` or else backpropagation will fail!\n",
    "        return {\"loss\": loss, \"preds\": preds, \"targets\": targets}\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # We need to compute and log metrics in this phase. If we compute metrics during training step, every epoch which is computationally ineficient\n",
    "        # instead can compute the metrics in the phase to just evaluate the metrics at the end of epoch\n",
    "        pass\n",
    "\n",
    "    def validation_step(self, batch: Any, batch_idx: int):\n",
    "\n",
    "        loss, preds, logits, targets, probs  = self.step(batch)\n",
    "\n",
    "        # log val metrics\n",
    "        acc = self.val_acc(preds, targets)\n",
    "        ece = self.val_ece(probs, targets)\n",
    "        entropy = self.val_entropy(logits)\n",
    "        self.log(\"val/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/ece\", ece, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val/entropy\", entropy, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return {\"loss\": loss, \"preds\": preds, \"targets\": targets}\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        acc = self.val_acc.compute()  # get val accuracy from current epoch\n",
    "        self.val_acc_best(acc)\n",
    "\n",
    "        ece = self.val_ece.compute()  # get val accuracy from current epoch\n",
    "        self.val_ece_best(ece)\n",
    "\n",
    "        entropy = self.val_entropy.compute()  # get val accuracy from current epoch\n",
    "        self.val_entropy_best(entropy)\n",
    "\n",
    "        # log `*_best` metrics as a value through `.compute()` method, instead of as a metric object\n",
    "        # otherwise metric would be reset by lightning after each epoch\n",
    "        self.log(\"val/acc_best\", self.val_acc_best.compute(), sync_dist=True, prog_bar=True)\n",
    "        self.log(\"val/ece_best\", self.val_ece_best.compute(), sync_dist=True, prog_bar=True)\n",
    "        self.log(\"val/entropy_best\", self.val_entropy_best.compute(), sync_dist=True, prog_bar=True)\n",
    "\n",
    "    def on_test_epoch_start(self):\n",
    "        if self.calibrator is None:\n",
    "            return\n",
    "\n",
    "        val_x, val_y = self.trainer.datamodule.data_val[:]\n",
    "        val_x, val_y = val_x.to(self.device), val_y.squeeze(-1).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.forward(val_x)\n",
    "            val_pred = F.softmax(logits, dim=-1)\n",
    "\n",
    "        with torch.enable_grad():\n",
    "            self.calibrator.train(val_pred, val_y)\n",
    "\n",
    "    def test_step(self, batch: Any, batch_idx: int):\n",
    "        loss, preds, logits, targets, probs = self.step(batch)\n",
    "\n",
    "        # log test metrics\n",
    "        acc = self.test_acc(preds, targets)\n",
    "        ece = self.test_ece(probs, targets)\n",
    "        entropy = self.test_entropy(logits)\n",
    "\n",
    "        x, _ = batch\n",
    "        kcal = self.test_kcal(logits, targets, x)\n",
    "\n",
    "        self.log(\"test/loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test/acc\", acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test/ece\", ece, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test/entropy\", entropy, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"test/kcal\", kcal, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # If post-hoc calibration method is chosen, apply it to model predictions\n",
    "        if self.calibrator:\n",
    "            pred_dist = F.softmax(logits, dim=-1)\n",
    "            with torch.no_grad():\n",
    "                calibrated_dists = self.calibrator(pred_dist)\n",
    "                calibrated_preds = torch.argmax(calibrated_dists, dim=-1)\n",
    "\n",
    "            calibrated_acc = self.test_calibrated_acc(calibrated_preds, targets)\n",
    "            calibrated_ece = self.test_calibrated_ece(calibrated_dists, targets)\n",
    "            calibrated_entropy = self.test_calibrated_entropy(calibrated_dists, is_dist=True)\n",
    "            calibrated_kcal = self.test_kcal(calibrated_dists, targets, x)\n",
    "\n",
    "            # log post-hoc calibrated test metrics\n",
    "            self.log(f\"test/calibrated_acc\", calibrated_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "            self.log(f\"test/calibrated_ece \", calibrated_ece , on_step=False, on_epoch=True, prog_bar=True)\n",
    "            self.log(f\"test/calibrated_entropy\", calibrated_entropy, on_step=False, on_epoch=True, prog_bar=True)\n",
    "            self.log(f\"test/calibrated_kcal\", calibrated_kcal, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return {\"loss\": loss, \"preds\": preds, \"targets\": targets}\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Reset metrics at the end of every epoch\n",
    "        self.train_acc.reset()\n",
    "        self.test_acc.reset()\n",
    "        self.val_acc.reset()\n",
    "\n",
    "        self.train_ece.reset()\n",
    "        self.test_ece.reset()\n",
    "        self.val_ece.reset()\n",
    "\n",
    "        self.train_entropy.reset()\n",
    "        self.test_entropy.reset()\n",
    "        self.val_entropy.reset()\n",
    "\n",
    "        self.test_kcal.reset()\n",
    "\n",
    "        if self.calibrator:\n",
    "            self.test_calibrated_acc.reset()\n",
    "            self.test_calibrated_ece.reset()\n",
    "            self.test_calibrated_entropy.reset()\n",
    "            self.test_calibrated_kcal.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Choose what optimizers and learning-rate schedulers to use in your optimization.\n",
    "        Normally you'd need one. But in the case of GANs or similar you might have multiple.\n",
    "\n",
    "        See examples here:\n",
    "            https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html#configure-optimizers\n",
    "        \"\"\"\n",
    "        return torch.optim.Adam(\n",
    "            params=self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56spr4IyNK-2"
   },
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uhdB9gSLDqL5"
   },
   "outputs": [],
   "source": [
    "# Calibration\n",
    "def _get_prediction_device(predictions):\n",
    "    \"\"\" Get the device of a prediction\n",
    "\n",
    "    Args:\n",
    "        predictions: a prediction of any type.\n",
    "\n",
    "    Returns:\n",
    "        device: the torch device that prediction is on.\n",
    "    \"\"\"\n",
    "    if issubclass(type(predictions), torch.distributions.distribution.Distribution):\n",
    "        with torch.no_grad():\n",
    "            device = predictions.sample().device    # Trick to get the device of a torch Distribution class because there is no interface for this\n",
    "    elif issubclass(type(predictions), dict):\n",
    "        assert len(predictions.keys()) != 0, \"Must have at least one element in the ensemble\"\n",
    "        device = _get_prediction_device(predictions[next(iter(predictions))])   # Return the device of the first element in the dictionary\n",
    "    else:\n",
    "        device = predictions.device\n",
    "    return device\n",
    "\n",
    "class Calibrator:\n",
    "    \"\"\" The abstract base class for all calibrator classes.\n",
    "\n",
    "    Args:\n",
    "        input_type (str): the input prediction type.\n",
    "            If input_type is 'auto' then it is automatically induced when Calibrator.train() or update() is called, it cannot be changed after the first call to train() or update().\n",
    "            Not all sub-classes support 'auto' input_type, so it is strongly recommended to explicitly specify the prediction type.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_type='auto'):\n",
    "        self.input_type = input_type\n",
    "        self.device = None\n",
    "\n",
    "    def _change_device(self, predictions):\n",
    "        \"\"\" Move everything into the same device as predictions, do nothing if they are already on the same device \"\"\"\n",
    "        # print(\"_change_device is deprecated \")\n",
    "        device = _get_prediction_device(predictions)\n",
    "        # device = self.get_device(predictions)\n",
    "        self.to(device)\n",
    "        self.device = device\n",
    "        return device\n",
    "\n",
    "\n",
    "    def to(self, device):\n",
    "        \"\"\" Move this class and all the tensors it owns to a specified device.\n",
    "\n",
    "        Args:\n",
    "            device (torch.device): the device to move this class to.\n",
    "        \"\"\"\n",
    "        assert False, \"Calibrator.to has not been implemented\"\n",
    "\n",
    "\n",
    "    def train(self, predictions, labels, *args, **kwargs):\n",
    "        \"\"\" The train abstract class. Learn the recalibration map based on labeled data.\n",
    "\n",
    "        This function uses the training data to learn any parameters that is necessary to transform a low quality (e.g. uncalibrated) prediction into a higher quality (e.g. calibrated) prediction.\n",
    "        It takes as input a set of predictions and the corresponding labels.\n",
    "        In addition, a few recalibration algorithms --- such as group calibration or multicalibration --- can take as input additional side features, and the transformation depends on the side feature.\n",
    "\n",
    "        Args:\n",
    "            predictions (object): a batched prediction object, must match the input_type argument when calling __init__.\n",
    "            labels (tensor): the labels with shape [batch_size]\n",
    "            side_feature (tensor): some calibrator instantiations can use additional side feature, when used it should be a tensor of shape [batch_size, n_features]\n",
    "\n",
    "        Returns:\n",
    "            object: an optional log object that contains information about training history.\n",
    "        \"\"\"\n",
    "        assert False, \"Calibrator.train has not been implemented\"\n",
    "\n",
    "    #\n",
    "    # If half_life is not None, then it is the number of calls to this function where the sample is discounted to 1/2 weight\n",
    "    # Not all calibration functions support half_life\n",
    "    def update(self, predictions, labels, *args, **kwargs):\n",
    "        \"\"\" Same as Calibrator.train, but updates the calibrator online with the new data (while train erases any existing data in the calibrator and learns it from scratch)\n",
    "\n",
    "        Args:\n",
    "            predictions (object): a batched prediction object, must match the input_type argument when calling __init__.\n",
    "            labels (tensor): the labels with shape [batch_size]\n",
    "            side_feature (tensor): some calibrator instantiations can use additional side feature, when used it should be a tensor of shape [batch_size, n_features]\n",
    "\n",
    "        Returns:\n",
    "            object: an optional log object that contains information about training history.\n",
    "        \"\"\"\n",
    "        assert False, \"Calibrator.update has not been implemented\"\n",
    "\n",
    "    # Input an array of shape [batch_size, num_classes], output the recalibrated array\n",
    "    # predictions should be in the same pytorch device\n",
    "    # If side_feature is not None when calling train, it shouldn't be None here either.\n",
    "    def __call__(self, predictions, *args, **kwargs):\n",
    "        \"\"\" Use the learned calibrator to transform new data.\n",
    "\n",
    "        Args:\n",
    "            predictions (prediction object): a batched prediction object, must match the input_type argument when calling __init__.\n",
    "            labels (tensor): the labels with shape [batch_size]\n",
    "            side_feature (tensor): some calibrator instantiations can use additional side feature, when used it should be a tensor of shape [batch_size, n_features]\n",
    "\n",
    "        Returns:\n",
    "            prediction object: the transformed predictions\n",
    "        \"\"\"\n",
    "        assert False, \"Calibrator.__call__ has not been implemented\"\n",
    "\n",
    "    def check_type(self, predictions):\n",
    "        \"\"\" Checks that the prediction has the correct shape specified by input_type.\n",
    "\n",
    "        Args:\n",
    "            predictions (prediction object): a batched prediction object, must match the input_type argument when calling __init__.\n",
    "        \"\"\"\n",
    "        if self.input_type == 'point':\n",
    "            assert len(predictions.shape) == 1, \"Point prediction should have shape [batch_size]\"\n",
    "        elif self.input_type == 'interval':\n",
    "            assert len(predictions.shape) == 2 and predictions.shape[1] == 2, \"interval predictions should have shape [batch_size, 2]\"\n",
    "        elif self.input_type == 'quantile':\n",
    "            assert len(predictions.shape) == 2 or (len(predictions.shape) == 3 and predictions.shape[2] == 2), \"quantile predictions should have shape [batch_size, num_quantile] or [batch_size, num_quantile, 2]\"\n",
    "        elif self.input_type == 'distribution':\n",
    "            # assert hasattr(predictions, 'cdf') and hasattr(predictions, 'icdf'), \"Distribution predictions should have a cdf and icdf method\"\n",
    "            assert hasattr(predictions, 'cdf') , \"Distribution predictions should have a cdf method\"\n",
    "\n",
    "    def assert_type(self, input_type, valid_types):\n",
    "        msg = \"Input data type not supported, input data type is %s, supported types are %s\" % (input_type, \" \".join(valid_types))\n",
    "        assert input_type in valid_types, msg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TemperatureScaling(Calibrator):\n",
    "    \"\"\" The class to recalibrate a categorical prediction with temperature scaling\n",
    "\n",
    "    Temeprature scaling is often the algorithm of choice when calibrating predictions from deep neural networks.\n",
    "    The only learnable parameter --- the temperature parameter $T$ --- is tuned to maximize the log-likelihood of the labels.\n",
    "    Temperature scaling requires very few samples to train because it only learns a single parameter $T$, yet despite the simplcity,\n",
    "    empirical results show that temperature scaling achieves low calibration error when applied to deep network predictions.\n",
    "\n",
    "    Args:\n",
    "        verbose (bool): if verbose=True print detailed messsages\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=False):\n",
    "        super(TemperatureScaling, self).__init__(input_type='categorical')\n",
    "        self.verbose = verbose\n",
    "        self.temperature = None\n",
    "\n",
    "    def train(self, predictions, labels, *args, **kwargs):\n",
    "        \"\"\" Find the optimal temperature with gradient descent.\n",
    "\n",
    "        Args:\n",
    "            predictions (tensor): a batch of categorical predictions with shape [batch_size, num_classes]\n",
    "            labels (tensor): a batch of labels with shape [batch_size]\n",
    "        \"\"\"\n",
    "        # Use gradient descent to find the optimal temperature\n",
    "        # Can add bisection option in the future, since it should be considerably faster\n",
    "        self.to(predictions)\n",
    "\n",
    "        self.temperature = torch.ones(1, 1, requires_grad=True, device=self.device)\n",
    "        optim = torch.optim.Adam([self.temperature], lr=1e-3)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', patience=3, threshold=1e-6, factor=0.5)\n",
    "\n",
    "        log_prediction = torch.log(predictions + 1e-10).detach()\n",
    "\n",
    "        # Iterate at most 100k iterations, but expect to stop early\n",
    "        for iteration in range(100000):\n",
    "            optim.zero_grad()\n",
    "            adjusted_predictions = log_prediction / self.temperature\n",
    "            loss = F.cross_entropy(adjusted_predictions, labels)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            lr_scheduler.step(loss)\n",
    "\n",
    "            # Hitchhike the lr scheduler to terminate if no progress\n",
    "            if optim.param_groups[0]['lr'] < 1e-6:\n",
    "                break\n",
    "            if self.verbose and iteration % 100 == 0:\n",
    "                print(\"Iteration %d, lr=%.5f, NLL=%.3f\" % (iteration, optim.param_groups[0]['lr'], loss.cpu().item()))\n",
    "\n",
    "    def __call__(self, predictions, *args, **kwargs):\n",
    "        \"\"\" Use the learned temperature to calibrate the predictions.\n",
    "\n",
    "        Only use this after calling TemperatureScaling.train.\n",
    "\n",
    "        Args:\n",
    "            predictions (tensor): a batch of categorical predictions with shape [batch_size, num_classes]\n",
    "\n",
    "        Returns:\n",
    "            tensor: the calibrated categorical prediction, it should have the same shape as the input predictions\n",
    "        \"\"\"\n",
    "        if self.temperature is None:\n",
    "            print(\"Error: need to first train before calling this function\")\n",
    "        self.to(predictions)\n",
    "        log_prediction = torch.log(predictions + 1e-10)\n",
    "        return torch.softmax(log_prediction / self.temperature, dim=1)\n",
    "\n",
    "    def to(self, device):\n",
    "        \"\"\" Move all assets of this class to a torch device.\n",
    "\n",
    "        Args:\n",
    "            device (device): the torch device (such as torch.device('cpu'))\n",
    "        \"\"\"\n",
    "        device = _get_prediction_device(device)\n",
    "        if self.temperature is not None:\n",
    "            self.temperature.to(device)\n",
    "        self.device = device\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrF_3LpaW4rY"
   },
   "source": [
    "# Data Module\n",
    "\n",
    "We only use single datamodule and extends it to other dataset defining new dataset loading function to preprocess it\n",
    "\n",
    "TODO: define new load function and add the function name to classification_load_funs and add the dimension to classification_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TCKWZGPDDqL6"
   },
   "outputs": [],
   "source": [
    "# Data Module\n",
    "from typing import Optional, Tuple\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Dataset, random_split, TensorDataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import transforms\n",
    "from functools import partial\n",
    "class ClassificationDataModule(LightningDataModule):\n",
    "    \"\"\"Datamodule for classification datasets.\n",
    "\n",
    "    A DataModule implements 5 key methods:\n",
    "        - prepare_data (things to do on 1 GPU/TPU, not on every GPU/TPU in distributed mode)\n",
    "        - setup (things to do on every accelerator in distributed mode)\n",
    "        - train_dataloader (the training dataloader)\n",
    "        - val_dataloader (the validation dataloader(s))\n",
    "        - test_dataloader (the test dataloader(s))\n",
    "\n",
    "    This allows you to share a full dataset without explaining how to download,\n",
    "    split, transform and process the data.\n",
    "\n",
    "    Read the docs:\n",
    "        https://pytorch-lightning.readthedocs.io/en/latest/extensions/datamodules.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_name: Optional[str] = None,\n",
    "        data_dir: str = \"data/\",\n",
    "        random_seed: Optional[int] = 1,\n",
    "        train_val_test_split: Tuple[float, float, float] = (0.7, 0.1, 0.2),\n",
    "        batch_size: int = 64,\n",
    "        test_batch_size: int = 128,\n",
    "        normalize: bool = True,\n",
    "        num_workers: int = 0,\n",
    "        pin_memory: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert np.isclose(sum(train_val_test_split), 1), f\"Train_val_test_split must sum to 1. Got {train_val_test_split} with sum {sum(train_val_test_split):0.5f}.\"\n",
    "\n",
    "        # this line allows to access init params with 'self.hparams' attribute\n",
    "        self.save_hyperparameters(logger=False)\n",
    "\n",
    "        self.data_train: Optional[Dataset] = None\n",
    "        self.data_val: Optional[Dataset] = None\n",
    "        self.data_test: Optional[Dataset] = None\n",
    "\n",
    "        self.input_size: int = classification_shapes[dataset_name][0]\n",
    "        self.label_size: int = classification_shapes[dataset_name][1]\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    @property\n",
    "    def dataset_type(self) -> str:\n",
    "        return \"regression\"\n",
    "\n",
    "    def prepare_data(self):\n",
    "        \"\"\"Download data if needed.\n",
    "\n",
    "        This method is called only from a single GPU.\n",
    "        Do not use it to assign state (self.x = y).\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        \"\"\"Load data. Set variables: `self.data_train`, `self.data_val`, `self.data_test`.\n",
    "\n",
    "        This method is called by lightning when doing `trainer.fit()` and `trainer.test()`,\n",
    "        so be careful not to execute the random split twice! The `stage` can be used to\n",
    "        differentiate whether it's called before trainer.fit()` or `trainer.test()`.\n",
    "        \"\"\"\n",
    "\n",
    "        # load datasets only if they're not loaded already\n",
    "        if not self.data_train and not self.data_val and not self.data_test:\n",
    "            loader_fun = classification_load_funs[self.hparams.dataset_name]\n",
    "            X, y = loader_fun(self.hparams.data_dir)\n",
    "            if self.hparams.normalize:\n",
    "                std = X.std(axis=0)\n",
    "                zeros = np.isclose(std, 0.)\n",
    "                X[:, ~zeros] = (X[:, ~zeros] - X[:, ~zeros].mean(axis=0)) / X[:, ~zeros].std(axis=0)\n",
    "                X[:, zeros] = 0.\n",
    "            if y.ndim == 1:\n",
    "                y = y.reshape(-1, 1)\n",
    "            # Split based on initialized ratio\n",
    "            dataset = TensorDataset(torch.Tensor(X), torch.Tensor(y).long())\n",
    "            lengths = [int(len(X) * p) for p in self.hparams.train_val_test_split]\n",
    "            lengths[-1] += len(X) - sum(lengths)  # fix any rounding errors\n",
    "            self.data_train, self.data_val, self.data_test = random_split(\n",
    "                dataset=dataset,\n",
    "                lengths=lengths,\n",
    "                generator=torch.Generator().manual_seed(self.hparams.random_seed),\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.data_train,\n",
    "            batch_size=self.hparams.batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.data_val,\n",
    "            batch_size=self.hparams.test_batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            dataset=self.data_test,\n",
    "            batch_size=self.hparams.test_batch_size,\n",
    "            num_workers=self.hparams.num_workers,\n",
    "            pin_memory=self.hparams.pin_memory,\n",
    "            shuffle=False,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "def _load_adult(data_dir):\n",
    "    \"\"\"\n",
    "    Attribute Information:\n",
    "    The dataset contains 16 columns\n",
    "    Target filed: Income\n",
    "    -- The income is divide into two classes: <=50K and >50K\n",
    "    Number of attributes: 14\n",
    "    -- These are the demographics and other features to describe a person\n",
    "    \"\"\"\n",
    "    data_file = os.path.join(data_dir, 'classification/adult/adult.data')\n",
    "    colnames = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"educational-num\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"gender\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\"native-country\",\"income\"]\n",
    "    data = pd.read_csv(data_file, header=None, names=colnames, skipinitialspace=True)\n",
    "    data = data.replace(\"?\", np.nan).dropna()\n",
    "    category_col =['workclass', 'education','marital-status', 'occupation',\n",
    "                  'relationship', 'race', 'gender', 'native-country']\n",
    "    b, c = np.unique(data['income'], return_inverse=True)\n",
    "    data['income'] = c # turn into binary [0,1]\n",
    "\n",
    "    def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "      dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "      res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "      res = res.drop([feature_to_encode], axis=1)\n",
    "      return res\n",
    "\n",
    "    for feature in category_col:\n",
    "        data = encode_and_bind(data, feature)\n",
    "\n",
    "    y = data['income'].to_numpy()\n",
    "    data = data.drop('income', axis=1)\n",
    "    X = data.to_numpy().astype(float)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "classification_load_funs = {\n",
    "    \"adult\": _load_adult}\n",
    "\n",
    "classification_shapes = {\n",
    "    \"wdbc\": (30, 2),\n",
    "    \"adult\": (104, 2),\n",
    "    \"heart-disease\": (23, 5),\n",
    "    \"online-shoppers\": (28, 2),\n",
    "    \"dry-bean\": (16, 7)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Db5N2b_NpHhV"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BzbU1vYHpGVq"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "from typing import List, Sequence\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import rich.syntax\n",
    "import rich.tree\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "import wandb\n",
    "from pytorch_lightning.loggers.logger import Logger ## Used for storing multiple loggers\n",
    "\n",
    "\n",
    "def get_logger(name=__name__) -> logging.Logger:\n",
    "    \"\"\"Initializes multi-GPU-friendly python command line logger.\"\"\"\n",
    "\n",
    "    logger = logging.getLogger(name)\n",
    "\n",
    "    # this ensures all logging levels get marked with the rank zero decorator\n",
    "    # otherwise logs would get multiplied for each GPU process in multi-GPU setup\n",
    "    for level in (\n",
    "        \"debug\",\n",
    "        \"info\",\n",
    "        \"warning\",\n",
    "        \"error\",\n",
    "        \"exception\",\n",
    "        \"fatal\",\n",
    "        \"critical\",\n",
    "    ):\n",
    "        setattr(logger, level, rank_zero_only(getattr(logger, level)))\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "log = get_logger(__name__)\n",
    "\n",
    "\n",
    "def extras(config: DictConfig) -> None:\n",
    "    \"\"\"Applies optional utilities, controlled by config flags.\n",
    "\n",
    "    Utilities:\n",
    "    - Ignoring python warnings\n",
    "    - Rich config printing\n",
    "    \"\"\"\n",
    "\n",
    "    # disable python warnings if <config.ignore_warnings=True>\n",
    "    if config.get(\"ignore_warnings\"):\n",
    "        log.info(\"Disabling python warnings! <config.ignore_warnings=True>\")\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # pretty print config tree using Rich library if <config.print_config=True>\n",
    "    if config.get(\"print_config\"):\n",
    "        log.info(\"Printing config tree with Rich! <config.print_config=True>\")\n",
    "        print_config(config, resolve=True)\n",
    "\n",
    "\n",
    "@rank_zero_only\n",
    "def print_config(\n",
    "    config: DictConfig,\n",
    "    print_order: Sequence[str] = (\n",
    "        \"datamodule\",\n",
    "        \"model\",\n",
    "        \"callbacks\",\n",
    "        \"logger\",\n",
    "        \"trainer\",\n",
    "    ),\n",
    "    resolve: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"Prints content of DictConfig using Rich library and its tree structure.\n",
    "\n",
    "    Args:\n",
    "        config (DictConfig): Configuration composed by Hydra.\n",
    "        print_order (Sequence[str], optional): Determines in what order config components are printed.\n",
    "        resolve (bool, optional): Whether to resolve reference fields of DictConfig.\n",
    "    \"\"\"\n",
    "\n",
    "    style = \"dim\"\n",
    "    tree = rich.tree.Tree(\"CONFIG\", style=style, guide_style=style)\n",
    "\n",
    "    quee = []\n",
    "\n",
    "    for field in print_order:\n",
    "        quee.append(field) if field in config else log.info(f\"Field '{field}' not found in config\")\n",
    "\n",
    "    for field in config:\n",
    "        if field not in quee:\n",
    "            quee.append(field)\n",
    "\n",
    "    for field in quee:\n",
    "        branch = tree.add(field, style=style, guide_style=style)\n",
    "\n",
    "        config_group = config[field]\n",
    "        if isinstance(config_group, DictConfig):\n",
    "            branch_content = OmegaConf.to_yaml(config_group, resolve=resolve)\n",
    "        else:\n",
    "            branch_content = str(config_group)\n",
    "\n",
    "        branch.add(rich.syntax.Syntax(branch_content, \"yaml\"))\n",
    "\n",
    "    rich.print(tree)\n",
    "\n",
    "    with open(\"config_tree.log\", \"w\") as file:\n",
    "        rich.print(tree, file=file)\n",
    "\n",
    "\n",
    "@rank_zero_only\n",
    "def log_hyperparameters(\n",
    "    config: DictConfig,\n",
    "    model: pl.LightningModule,\n",
    "    datamodule: pl.LightningDataModule,\n",
    "    trainer: pl.Trainer,\n",
    "    callbacks: List[pl.Callback],\n",
    "    logger: List[Logger],\n",
    ") -> None:\n",
    "    \"\"\"Controls which config parts are saved by Lightning loggers.\n",
    "\n",
    "    Additionaly saves:\n",
    "    - number of model parameters\n",
    "    \"\"\"\n",
    "\n",
    "    if not trainer.logger:\n",
    "        return\n",
    "\n",
    "    hparams = {}\n",
    "\n",
    "    # choose which parts of hydra config will be saved to loggers\n",
    "    hparams[\"model\"] = config[\"model\"]\n",
    "\n",
    "    # save number of model parameters\n",
    "    hparams[\"model/params/total\"] = sum(p.numel() for p in model.parameters())\n",
    "    hparams[\"model/params/trainable\"] = sum(\n",
    "        p.numel() for p in model.parameters() if p.requires_grad\n",
    "    )\n",
    "    hparams[\"model/params/non_trainable\"] = sum(\n",
    "        p.numel() for p in model.parameters() if not p.requires_grad\n",
    "    )\n",
    "\n",
    "    hparams[\"datamodule\"] = config[\"datamodule\"]\n",
    "    hparams[\"trainer\"] = config[\"trainer\"]\n",
    "\n",
    "    if \"seed\" in config:\n",
    "        hparams[\"seed\"] = config[\"seed\"]\n",
    "    if \"callbacks\" in config:\n",
    "        hparams[\"callbacks\"] = config[\"callbacks\"]\n",
    "\n",
    "    # send hparams to all loggers\n",
    "    trainer.logger.log_hyperparams(hparams)\n",
    "\n",
    "\n",
    "def finish(\n",
    "    config: DictConfig,\n",
    "    model: pl.LightningModule,\n",
    "    datamodule: pl.LightningDataModule,\n",
    "    trainer: pl.Trainer,\n",
    "    callbacks: List[pl.Callback],\n",
    "    logger: List[Logger],\n",
    ") -> None:\n",
    "    \"\"\"Makes sure everything closed properly.\"\"\"\n",
    "\n",
    "    # without this sweeps with wandb logger might crash!\n",
    "    for lg in logger:\n",
    "        if isinstance(lg, pl.loggers.wandb.WandbLogger):\n",
    "            import wandb\n",
    "            wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQmlW9Yxpqa-"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "c3Gy4fsSDqL7"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "import os\n",
    "from typing import List, Optional\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "from pytorch_lightning import (\n",
    "    Callback,\n",
    "    LightningDataModule,\n",
    "    LightningModule,\n",
    "    Trainer,\n",
    "    seed_everything,\n",
    ")\n",
    "from pytorch_lightning.loggers.logger import Logger ## Used for storing multiple loggers\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "import logging\n",
    "\n",
    "log = get_logger(__name__)\n",
    "\n",
    "\n",
    "def train(config: DictConfig) -> Optional[float]:\n",
    "    \"\"\"Contains the training pipeline. Can additionally evaluate model on a testset, using best\n",
    "    weights achieved during training.\n",
    "\n",
    "    Args:\n",
    "        config (DictConfig): Configuration composed by Hydra.\n",
    "\n",
    "    Returns:\n",
    "        Optional[float]: Metric score for hyperparameter optimization.\n",
    "    \"\"\"\n",
    "    # Set seed for random number generators in pytorch, numpy and python.random\n",
    "    if config.get(\"seed\"):\n",
    "        seed_everything(config.seed, workers=True)\n",
    "\n",
    "    # Convert relative ckpt path to absolute path if necessary\n",
    "    ckpt_path = config.trainer.get(\"resume_from_checkpoint\")\n",
    "    if ckpt_path and not os.path.isabs(ckpt_path):\n",
    "        config.trainer.resume_from_checkpoint = os.path.join(\n",
    "            hydra.utils.get_original_cwd(), ckpt_path\n",
    "        )\n",
    "    # Init lightning datamodule\n",
    "    log.info(f\"Instantiating datamodule <{config.datamodule._target_}>\")\n",
    "    datamodule = ClassificationDataModule(dataset_name = config.datamodule.dataset_name, data_dir = config.datamodule.data_dir)\n",
    "\n",
    "\n",
    "    # Init lightning model\n",
    "    log.info(f\"Instantiating model <{config.model._target_}>\")\n",
    "    config.model.net.input_size = datamodule.input_size\n",
    "    config.model.net.output_size = datamodule.label_size\n",
    "    model = ClassificationLitModule(net = SimpleDenseNet(input_size =config.model.net.input_size, output_size = config.model.net.output_size),\n",
    "                                                         criterion = globals()[config.model.criterion._target_](), calibrator = globals()[config.model.calibrator._target_]())\n",
    "\n",
    "\n",
    "    # Init lightning callbacks\n",
    "    callbacks: List[Callback] = []\n",
    "    if \"callbacks\" in config:\n",
    "        for _, cb_conf in config.callbacks.items():\n",
    "            if \"_target_\" in cb_conf:\n",
    "                log.info(f\"Instantiating callback <{cb_conf._target_}>\")\n",
    "                callbacks.append(hydra.utils.instantiate(cb_conf))\n",
    "\n",
    "    # Init lightning loggers\n",
    "    logger: List[Logger] = []\n",
    "    if \"logger\" in config:\n",
    "        for _, lg_conf in config.logger.items():\n",
    "            if \"_target_\" in lg_conf:\n",
    "                log.info(f\"Instantiating logger <{lg_conf._target_}>\")\n",
    "                logger.append(hydra.utils.instantiate(lg_conf))\n",
    "\n",
    "    # Init lightning trainer\n",
    "    log.info(f\"Instantiating trainer <{config.trainer._target_}>\")\n",
    "    trainer: Trainer = hydra.utils.instantiate(\n",
    "        config.trainer, callbacks=callbacks, logger=logger, _convert_=\"partial\"\n",
    "    )\n",
    "\n",
    "    # Send some parameters from config to all lightning loggers\n",
    "    log.info(\"Logging hyperparameters!\")\n",
    "    log_hyperparameters(\n",
    "        config=config,\n",
    "        model=model,\n",
    "        datamodule=datamodule,\n",
    "        trainer=trainer,\n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    if config.get(\"train\"):\n",
    "        log.info(\"Starting training!\")\n",
    "        trainer.fit(model=model, datamodule=datamodule)\n",
    "\n",
    "    # Get metric score for hyperparameter optimization\n",
    "    optimized_metric = config.get(\"optimized_metric\")\n",
    "    if optimized_metric and optimized_metric not in trainer.callback_metrics:\n",
    "        raise Exception(\n",
    "            \"Metric for hyperparameter optimization not found! \"\n",
    "            \"Make sure the `optimized_metric` in `hparams_search` config is correct!\"\n",
    "        )\n",
    "    score = trainer.callback_metrics.get(optimized_metric)\n",
    "\n",
    "    # Test the model\n",
    "    if config.get(\"test\"):\n",
    "        ckpt_path = \"best\"\n",
    "        if not config.get(\"train\") or config.trainer.get(\"fast_dev_run\"):\n",
    "            ckpt_path = None\n",
    "        log.info(\"Starting testing!\")\n",
    "        trainer.test(model=model, datamodule=datamodule, ckpt_path=ckpt_path)\n",
    "\n",
    "    # Make sure everything closed properly\n",
    "    log.info(\"Finalizing!\")\n",
    "    finish(\n",
    "        config=config,\n",
    "        model=model,\n",
    "        datamodule=datamodule,\n",
    "        trainer=trainer,\n",
    "        callbacks=callbacks,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # Print path to best checkpoint\n",
    "    if not config.trainer.get(\"fast_dev_run\") and config.get(\"train\"):\n",
    "        log.info(f\"Best model ckpt at {trainer.checkpoint_callback.best_model_path}\")\n",
    "\n",
    "    # Return metric score for hyperparameter optimization\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xPUsnfSGjvrU",
    "outputId": "185c63dc-9ab2-43f0-c0fb-1e9a14baf427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "31b53048339a44409a3070fa58421593",
      "406f2f2c9a004ca492bf01d9ff75f1d7"
     ]
    },
    "id": "C_CdlLMaDqL7",
    "outputId": "2c78723b-ec15-413f-db7d-48cd174530b3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 12345\n",
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/local/scratch/a/ko120/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /local/scratch/a/ko120/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240811_160132-oduxo2rl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ko120/DM_Benchmark/runs/oduxo2rl' target=\"_blank\">classification_mixed</a></strong> to <a href='https://wandb.ai/ko120/DM_Benchmark' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ko120/DM_Benchmark' target=\"_blank\">https://wandb.ai/ko120/DM_Benchmark</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ko120/DM_Benchmark/runs/oduxo2rl' target=\"_blank\">https://wandb.ai/ko120/DM_Benchmark/runs/oduxo2rl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name                    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                                 </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0  </span>│ net                     │ SimpleDenseNet                       │  160 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1  </span>│ net.model               │ Sequential                           │  160 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2  </span>│ net.model.0             │ Linear                               │ 26.9 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3  </span>│ net.model.1             │ BatchNorm1d                          │    512 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4  </span>│ net.model.2             │ ReLU                                 │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5  </span>│ net.model.3             │ Linear                               │ 65.8 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6  </span>│ net.model.4             │ BatchNorm1d                          │    512 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7  </span>│ net.model.5             │ ReLU                                 │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8  </span>│ net.model.6             │ Linear                               │ 65.8 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9  </span>│ net.model.7             │ BatchNorm1d                          │    512 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 10 </span>│ net.model.8             │ ReLU                                 │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 11 </span>│ net.model.9             │ Linear                               │    514 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 12 </span>│ train_acc               │ BinaryAccuracy                       │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 13 </span>│ val_acc                 │ BinaryAccuracy                       │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 14 </span>│ test_acc                │ BinaryAccuracy                       │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 15 </span>│ train_ece               │ MulticlassCalibrationError           │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 16 </span>│ val_ece                 │ MulticlassCalibrationError           │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 17 </span>│ test_ece                │ MulticlassCalibrationError           │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 18 </span>│ train_entropy           │ ShannonEntropyError                  │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 19 </span>│ val_entropy             │ ShannonEntropyError                  │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 20 </span>│ test_entropy            │ ShannonEntropyError                  │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 21 </span>│ test_kcal               │ ClassificationKernelCalibrationError │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 22 </span>│ val_acc_best            │ MaxMetric                            │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 23 </span>│ val_ece_best            │ MinMetric                            │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 24 </span>│ val_entropy_best        │ MinMetric                            │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 25 </span>│ test_calibrated_acc     │ BinaryAccuracy                       │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 26 </span>│ test_calibrated_ece     │ MulticlassCalibrationError           │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 27 </span>│ test_calibrated_entropy │ ShannonEntropyError                  │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 28 </span>│ test_calibrated_kcal    │ ClassificationKernelCalibrationError │      0 │ train │\n",
       "└────┴─────────────────────────┴──────────────────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m  \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                                \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0 \u001b[0m\u001b[2m \u001b[0m│ net                     │ SimpleDenseNet                       │  160 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1 \u001b[0m\u001b[2m \u001b[0m│ net.model               │ Sequential                           │  160 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2 \u001b[0m\u001b[2m \u001b[0m│ net.model.0             │ Linear                               │ 26.9 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3 \u001b[0m\u001b[2m \u001b[0m│ net.model.1             │ BatchNorm1d                          │    512 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m4 \u001b[0m\u001b[2m \u001b[0m│ net.model.2             │ ReLU                                 │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m5 \u001b[0m\u001b[2m \u001b[0m│ net.model.3             │ Linear                               │ 65.8 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m6 \u001b[0m\u001b[2m \u001b[0m│ net.model.4             │ BatchNorm1d                          │    512 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m7 \u001b[0m\u001b[2m \u001b[0m│ net.model.5             │ ReLU                                 │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m8 \u001b[0m\u001b[2m \u001b[0m│ net.model.6             │ Linear                               │ 65.8 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m9 \u001b[0m\u001b[2m \u001b[0m│ net.model.7             │ BatchNorm1d                          │    512 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m10\u001b[0m\u001b[2m \u001b[0m│ net.model.8             │ ReLU                                 │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m11\u001b[0m\u001b[2m \u001b[0m│ net.model.9             │ Linear                               │    514 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m12\u001b[0m\u001b[2m \u001b[0m│ train_acc               │ BinaryAccuracy                       │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m13\u001b[0m\u001b[2m \u001b[0m│ val_acc                 │ BinaryAccuracy                       │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m14\u001b[0m\u001b[2m \u001b[0m│ test_acc                │ BinaryAccuracy                       │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m15\u001b[0m\u001b[2m \u001b[0m│ train_ece               │ MulticlassCalibrationError           │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m16\u001b[0m\u001b[2m \u001b[0m│ val_ece                 │ MulticlassCalibrationError           │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m17\u001b[0m\u001b[2m \u001b[0m│ test_ece                │ MulticlassCalibrationError           │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m18\u001b[0m\u001b[2m \u001b[0m│ train_entropy           │ ShannonEntropyError                  │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m19\u001b[0m\u001b[2m \u001b[0m│ val_entropy             │ ShannonEntropyError                  │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m20\u001b[0m\u001b[2m \u001b[0m│ test_entropy            │ ShannonEntropyError                  │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m21\u001b[0m\u001b[2m \u001b[0m│ test_kcal               │ ClassificationKernelCalibrationError │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m22\u001b[0m\u001b[2m \u001b[0m│ val_acc_best            │ MaxMetric                            │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m23\u001b[0m\u001b[2m \u001b[0m│ val_ece_best            │ MinMetric                            │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m24\u001b[0m\u001b[2m \u001b[0m│ val_entropy_best        │ MinMetric                            │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m25\u001b[0m\u001b[2m \u001b[0m│ test_calibrated_acc     │ BinaryAccuracy                       │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m26\u001b[0m\u001b[2m \u001b[0m│ test_calibrated_ece     │ MulticlassCalibrationError           │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m27\u001b[0m\u001b[2m \u001b[0m│ test_calibrated_entropy │ ShannonEntropyError                  │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m28\u001b[0m\u001b[2m \u001b[0m│ test_calibrated_kcal    │ ClassificationKernelCalibrationError │      0 │ train │\n",
       "└────┴─────────────────────────┴──────────────────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 160 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 160 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 29                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 160 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 160 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 29                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "087a17036616419e8d818d5c814ee041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/local/scratch/a/ko120/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_co\n",
       "nnector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/local/scratch/a/ko120/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_co\n",
       "nnector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the \n",
       "value of the `num_workers` argument` to `num_workers=23` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">&gt; <span style=\"color: #008000; text-decoration-color: #008000\">/tmp/ipykernel_1999417/466582797.py</span>(98)<span style=\"color: #008080; text-decoration-color: #008080\">step</span><span style=\"color: #000080; text-decoration-color: #000080\">()</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">     96 </span><span style=\"color: #800000; text-decoration-color: #800000\">        </span>pdb<span style=\"color: #000080; text-decoration-color: #000080\">.</span>set_trace<span style=\"color: #000080; text-decoration-color: #000080\">()</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">     97 </span><span style=\"color: #800000; text-decoration-color: #800000\">        # Question should we disable taking gradient for preds and probs since it is only being used on </span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">computing metrics?</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">---&gt; 98 </span><span style=\"color: #800000; text-decoration-color: #800000\">        </span>preds <span style=\"color: #000080; text-decoration-color: #000080\">=</span> torch<span style=\"color: #000080; text-decoration-color: #000080\">.</span>argmax<span style=\"color: #000080; text-decoration-color: #000080\">(</span>logits<span style=\"color: #000080; text-decoration-color: #000080\">,</span> dim<span style=\"color: #000080; text-decoration-color: #000080\">=-</span><span style=\"color: #008080; text-decoration-color: #008080\">1</span><span style=\"color: #000080; text-decoration-color: #000080\">)</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">     99 </span><span style=\"color: #800000; text-decoration-color: #800000\">        </span>probs <span style=\"color: #000080; text-decoration-color: #000080\">=</span> F<span style=\"color: #000080; text-decoration-color: #000080\">.</span>softmax<span style=\"color: #000080; text-decoration-color: #000080\">(</span>logits<span style=\"color: #000080; text-decoration-color: #000080\">,</span> dim<span style=\"color: #000080; text-decoration-color: #000080\">=-</span><span style=\"color: #008080; text-decoration-color: #008080\">1</span><span style=\"color: #000080; text-decoration-color: #000080\">)</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">    100 </span>\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "\u001b<span style=\"font-weight: bold\">[</span>0m\n",
       "</pre>\n"
      ],
      "text/plain": [
       "> \u001b[32m/tmp/ipykernel_1999417/466582797.py\u001b[0m(98)\u001b[36mstep\u001b[0m\u001b[34m()\u001b[0m\n",
       "\u001b[32m     96 \u001b[0m\u001b[31m        \u001b[0mpdb\u001b[34m.\u001b[0mset_trace\u001b[34m(\u001b[0m\u001b[34m)\u001b[0m\n",
       "\u001b[32m     97 \u001b[0m\u001b[31m        \u001b[0m\u001b[31m# Question should we disable taking gradient for preds and probs since it is only being used on \u001b[0m\n",
       "\u001b[31mcomputing metrics?\u001b[0m\n",
       "\u001b[32m---> 98 \u001b[0m\u001b[31m        \u001b[0mpreds \u001b[34m=\u001b[0m torch\u001b[34m.\u001b[0margmax\u001b[34m(\u001b[0mlogits\u001b[34m,\u001b[0m dim\u001b[34m=\u001b[0m\u001b[34m-\u001b[0m\u001b[36m1\u001b[0m\u001b[34m)\u001b[0m\n",
       "\u001b[32m     99 \u001b[0m\u001b[31m        \u001b[0mprobs \u001b[34m=\u001b[0m F\u001b[34m.\u001b[0msoftmax\u001b[34m(\u001b[0mlogits\u001b[34m,\u001b[0m dim\u001b[34m=\u001b[0m\u001b[34m-\u001b[0m\u001b[36m1\u001b[0m\u001b[34m)\u001b[0m\n",
       "\u001b[32m    100 \u001b[0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n",
       "\u001b\u001b[1m[\u001b[0m0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 125\u001b[0m\n\u001b[1;32m    122\u001b[0m config\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mwandb\u001b[38;5;241m.\u001b[39mproject \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDM_Benchmark\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Assuming train is a function that accepts this config\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m train(config)\n",
      "Cell \u001b[0;32mIn[8], line 122\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    121\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(model\u001b[38;5;241m=\u001b[39mmodel, datamodule\u001b[38;5;241m=\u001b[39mdatamodule)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Get metric score for hyperparameter optimization\u001b[39;00m\n\u001b[1;32m    125\u001b[0m optimized_metric \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimized_metric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_and_handle_interrupt(\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    540\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run(model, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_stage()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1052\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1049\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m val_loop\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mis_last_batch \u001b[38;5;241m=\u001b[39m data_fetcher\u001b[38;5;241m.\u001b[39mdone\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    390\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_step\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39m_call_strategy_hook(trainer, hook_name, \u001b[38;5;241m*\u001b[39mstep_args)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    322\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:411\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mvalidation_step(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[4], line 129\u001b[0m, in \u001b[0;36mClassificationLitModule.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: Any, batch_idx: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 129\u001b[0m     loss, preds, logits, targets, probs  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep(batch)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# log val metrics\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_acc(preds, targets)\n",
      "Cell \u001b[0;32mIn[4], line 98\u001b[0m, in \u001b[0;36mClassificationLitModule.step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     96\u001b[0m pdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Question should we disable taking gradient for preds and probs since it is only being used on computing metrics?\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     99\u001b[0m probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, preds, logits, y, probs\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/bdb.py:90\u001b[0m, in \u001b[0;36mBdb.trace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;66;03m# None\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_line(frame)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_call(frame, arg)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/bdb.py:114\u001b[0m, in \u001b[0;36mBdb.dispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke user function and return trace function for line event.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03mIf the debugger stops on the current line, invoke\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;124;03mself.user_line(). Raise BdbQuit if self.quitting is set.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03mReturn self.trace_dispatch to continue tracing in this scope.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_here(frame) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbreak_here(frame):\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_line(frame)\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquitting: \u001b[38;5;28;01mraise\u001b[39;00m BdbQuit\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrace_dispatch\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/pdb.py:329\u001b[0m, in \u001b[0;36mPdb.user_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_mainpyfile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbp_commands(frame):\n\u001b[0;32m--> 329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minteraction(frame, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/debugger.py:443\u001b[0m, in \u001b[0;36mPdb.interaction\u001b[0;34m(self, frame, tb_or_exc)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m tb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain exception must have a traceback\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hold_exceptions(_chained_exceptions):\n\u001b[0;32m--> 443\u001b[0m         OldPdb\u001b[38;5;241m.\u001b[39minteraction(\u001b[38;5;28mself\u001b[39m, frame, tb)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     OldPdb\u001b[38;5;241m.\u001b[39minteraction(\u001b[38;5;28mself\u001b[39m, frame, tb_or_exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/pdb.py:424\u001b[0m, in \u001b[0;36mPdb.interaction\u001b[0;34m(self, frame, traceback)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# if we have more commands to process, do not show the stack entry\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcmdqueue:\n\u001b[0;32m--> 424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_stack_entry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurindex])\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmdloop()\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforget()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/debugger.py:507\u001b[0m, in \u001b[0;36mPdb.print_stack_entry\u001b[0;34m(self, frame_lineno, prompt_prefix, context)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    506\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContext must be a positive integer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_stack_entry(frame_lineno, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, context), file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# vds: >>\u001b[39;00m\n\u001b[1;32m    510\u001b[0m frame, lineno \u001b[38;5;241m=\u001b[39m frame_lineno\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/file_proxy.py:43\u001b[0m, in \u001b[0;36mFileProxy.write\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lines:\n\u001b[1;32m     42\u001b[0m     console \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__console\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m console:\n\u001b[1;32m     44\u001b[0m         output \u001b[38;5;241m=\u001b[39m Text(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__ansi_decoder\u001b[38;5;241m.\u001b[39mdecode_line(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines\n\u001b[1;32m     46\u001b[0m         )\n\u001b[1;32m     47\u001b[0m         console\u001b[38;5;241m.\u001b[39mprint(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:865\u001b[0m, in \u001b[0;36mConsole.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Exit buffer context.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exit_buffer()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:823\u001b[0m, in \u001b[0;36mConsole._exit_buffer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Leave buffer context, and render content if required.\"\"\"\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_index \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_buffer()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:2007\u001b[0m, in \u001b[0;36mConsole._check_buffer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_jupyter:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjupyter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m-> 2007\u001b[0m     display(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_buffer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]))\n\u001b[1;32m   2008\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/jupyter.py:91\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(segments, text)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display \u001b[38;5;28;01mas\u001b[39;00m ipython_display\n\u001b[0;32m---> 91\u001b[0m     ipython_display(jupyter_renderable)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Handle the case where the Console has force_jupyter=True,\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# but IPython is not installed.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/display_functions.py:305\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;66;03m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[1;32m    304\u001b[0m             _merge(md_dict, metadata)\n\u001b[0;32m--> 305\u001b[0m         publish_display_data(data\u001b[38;5;241m=\u001b[39mformat_dict, metadata\u001b[38;5;241m=\u001b[39mmd_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_id:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisplayHandle(display_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/display_functions.py:93\u001b[0m, in \u001b[0;36mpublish_display_data\u001b[0;34m(data, metadata, source, transient, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[1;32m     91\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transient\n\u001b[0;32m---> 93\u001b[0m display_pub\u001b[38;5;241m.\u001b[39mpublish(\n\u001b[1;32m     94\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m     95\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     97\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:478\u001b[0m, in \u001b[0;36m_WandbInit._jupyter_setup.<locals>.publish\u001b[0;34m(data, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish\u001b[39m(data, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     ipython\u001b[38;5;241m.\u001b[39mdisplay_pub\u001b[38;5;241m.\u001b[39m_orig_publish(data, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39msave_display(\n\u001b[1;32m    481\u001b[0m         ipython\u001b[38;5;241m.\u001b[39mexecution_count, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata}\n\u001b[1;32m    482\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/ipykernel/zmqshell.py:103\u001b[0m, in \u001b[0;36mZMQDisplayPublisher.publish\u001b[0;34m(self, data, metadata, transient, update)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     83\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m ):\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Publish a display-data message\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m        If True, send an update_display_data message instead of display_data.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush_streams()\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/ipykernel/zmqshell.py:66\u001b[0m, in \u001b[0;36mZMQDisplayPublisher._flush_streams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     67\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/file_proxy.py:53\u001b[0m, in \u001b[0;36mFileProxy.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__buffer)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__console\u001b[38;5;241m.\u001b[39mprint(output)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__buffer[:]\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:1673\u001b[0m, in \u001b[0;36mConsole.print\u001b[0;34m(self, sep, end, style, justify, overflow, no_wrap, emoji, markup, highlight, width, height, crop, soft_wrap, new_line_start, *objects)\u001b[0m\n\u001b[1;32m   1671\u001b[0m     crop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m render_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_hooks[:]\n\u001b[0;32m-> 1673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m   1674\u001b[0m     renderables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_renderables(\n\u001b[1;32m   1675\u001b[0m         objects,\n\u001b[1;32m   1676\u001b[0m         sep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1681\u001b[0m         highlight\u001b[38;5;241m=\u001b[39mhighlight,\n\u001b[1;32m   1682\u001b[0m     )\n\u001b[1;32m   1683\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m render_hooks:\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:865\u001b[0m, in \u001b[0;36mConsole.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Exit buffer context.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exit_buffer()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:823\u001b[0m, in \u001b[0;36mConsole._exit_buffer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Leave buffer context, and render content if required.\"\"\"\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_index \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_buffer()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:2007\u001b[0m, in \u001b[0;36mConsole._check_buffer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_jupyter:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjupyter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m-> 2007\u001b[0m     display(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_buffer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]))\n\u001b[1;32m   2008\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/jupyter.py:91\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(segments, text)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display \u001b[38;5;28;01mas\u001b[39;00m ipython_display\n\u001b[0;32m---> 91\u001b[0m     ipython_display(jupyter_renderable)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Handle the case where the Console has force_jupyter=True,\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# but IPython is not installed.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/display_functions.py:305\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;66;03m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[1;32m    304\u001b[0m             _merge(md_dict, metadata)\n\u001b[0;32m--> 305\u001b[0m         publish_display_data(data\u001b[38;5;241m=\u001b[39mformat_dict, metadata\u001b[38;5;241m=\u001b[39mmd_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_id:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisplayHandle(display_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/display_functions.py:93\u001b[0m, in \u001b[0;36mpublish_display_data\u001b[0;34m(data, metadata, source, transient, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[1;32m     91\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transient\n\u001b[0;32m---> 93\u001b[0m display_pub\u001b[38;5;241m.\u001b[39mpublish(\n\u001b[1;32m     94\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m     95\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     97\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:478\u001b[0m, in \u001b[0;36m_WandbInit._jupyter_setup.<locals>.publish\u001b[0;34m(data, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish\u001b[39m(data, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     ipython\u001b[38;5;241m.\u001b[39mdisplay_pub\u001b[38;5;241m.\u001b[39m_orig_publish(data, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39msave_display(\n\u001b[1;32m    481\u001b[0m         ipython\u001b[38;5;241m.\u001b[39mexecution_count, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata}\n\u001b[1;32m    482\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/ipykernel/zmqshell.py:103\u001b[0m, in \u001b[0;36mZMQDisplayPublisher.publish\u001b[0;34m(self, data, metadata, transient, update)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     83\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m ):\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Publish a display-data message\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m        If True, send an update_display_data message instead of display_data.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush_streams()\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/ipykernel/zmqshell.py:66\u001b[0m, in \u001b[0;36mZMQDisplayPublisher._flush_streams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     67\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/file_proxy.py:53\u001b[0m, in \u001b[0;36mFileProxy.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__buffer)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__console\u001b[38;5;241m.\u001b[39mprint(output)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__buffer[:]\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:1673\u001b[0m, in \u001b[0;36mConsole.print\u001b[0;34m(self, sep, end, style, justify, overflow, no_wrap, emoji, markup, highlight, width, height, crop, soft_wrap, new_line_start, *objects)\u001b[0m\n\u001b[1;32m   1671\u001b[0m     crop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m render_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_hooks[:]\n\u001b[0;32m-> 1673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m   1674\u001b[0m     renderables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_renderables(\n\u001b[1;32m   1675\u001b[0m         objects,\n\u001b[1;32m   1676\u001b[0m         sep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1681\u001b[0m         highlight\u001b[38;5;241m=\u001b[39mhighlight,\n\u001b[1;32m   1682\u001b[0m     )\n\u001b[1;32m   1683\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m render_hooks:\n",
      "    \u001b[0;31m[... skipping similar frames: Console.__exit__ at line 865 (266 times), Console._check_buffer at line 2007 (266 times), Console._exit_buffer at line 823 (266 times), display at line 91 (266 times), ZMQDisplayPublisher._flush_streams at line 66 (265 times), display at line 305 (265 times), FileProxy.flush at line 53 (265 times), Console.print at line 1673 (265 times), _WandbInit._jupyter_setup.<locals>.publish at line 478 (265 times), ZMQDisplayPublisher.publish at line 103 (265 times), publish_display_data at line 93 (265 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/display_functions.py:305\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;66;03m# kwarg-specified metadata gets precedence\u001b[39;00m\n\u001b[1;32m    304\u001b[0m             _merge(md_dict, metadata)\n\u001b[0;32m--> 305\u001b[0m         publish_display_data(data\u001b[38;5;241m=\u001b[39mformat_dict, metadata\u001b[38;5;241m=\u001b[39mmd_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_id:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisplayHandle(display_id)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/display_functions.py:93\u001b[0m, in \u001b[0;36mpublish_display_data\u001b[0;34m(data, metadata, source, transient, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transient:\n\u001b[1;32m     91\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransient\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m transient\n\u001b[0;32m---> 93\u001b[0m display_pub\u001b[38;5;241m.\u001b[39mpublish(\n\u001b[1;32m     94\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[1;32m     95\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     97\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:478\u001b[0m, in \u001b[0;36m_WandbInit._jupyter_setup.<locals>.publish\u001b[0;34m(data, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish\u001b[39m(data, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 478\u001b[0m     ipython\u001b[38;5;241m.\u001b[39mdisplay_pub\u001b[38;5;241m.\u001b[39m_orig_publish(data, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotebook\u001b[38;5;241m.\u001b[39msave_display(\n\u001b[1;32m    481\u001b[0m         ipython\u001b[38;5;241m.\u001b[39mexecution_count, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata}\n\u001b[1;32m    482\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/ipykernel/zmqshell.py:103\u001b[0m, in \u001b[0;36mZMQDisplayPublisher.publish\u001b[0;34m(self, data, metadata, transient, update)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     83\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     update\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     87\u001b[0m ):\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Publish a display-data message\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m        If True, send an update_display_data message instead of display_data.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush_streams()\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/ipykernel/zmqshell.py:66\u001b[0m, in \u001b[0;36mZMQDisplayPublisher._flush_streams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_flush_streams\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"flush IO Streams prior to display\"\"\"\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     67\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/file_proxy.py:53\u001b[0m, in \u001b[0;36mFileProxy.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__buffer)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__console\u001b[38;5;241m.\u001b[39mprint(output)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__buffer[:]\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:1673\u001b[0m, in \u001b[0;36mConsole.print\u001b[0;34m(self, sep, end, style, justify, overflow, no_wrap, emoji, markup, highlight, width, height, crop, soft_wrap, new_line_start, *objects)\u001b[0m\n\u001b[1;32m   1671\u001b[0m     crop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m render_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_hooks[:]\n\u001b[0;32m-> 1673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m   1674\u001b[0m     renderables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collect_renderables(\n\u001b[1;32m   1675\u001b[0m         objects,\n\u001b[1;32m   1676\u001b[0m         sep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1681\u001b[0m         highlight\u001b[38;5;241m=\u001b[39mhighlight,\n\u001b[1;32m   1682\u001b[0m     )\n\u001b[1;32m   1683\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m render_hooks:\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:865\u001b[0m, in \u001b[0;36mConsole.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Exit buffer context.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exit_buffer()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:823\u001b[0m, in \u001b[0;36mConsole._exit_buffer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Leave buffer context, and render content if required.\"\"\"\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_index \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 823\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_buffer()\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/console.py:2007\u001b[0m, in \u001b[0;36mConsole._check_buffer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_jupyter:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjupyter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m-> 2007\u001b[0m     display(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_buffer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]))\n\u001b[1;32m   2008\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/rich/jupyter.py:91\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(segments, text)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display \u001b[38;5;28;01mas\u001b[39;00m ipython_display\n\u001b[0;32m---> 91\u001b[0m     ipython_display(jupyter_renderable)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Handle the case where the Console has force_jupyter=True,\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# but IPython is not installed.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m(obj, include\u001b[38;5;241m=\u001b[39minclude, exclude\u001b[38;5;241m=\u001b[39mexclude)\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/IPython/core/formatters.py:148\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    145\u001b[0m format_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    146\u001b[0m md_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mipython_display_formatter(obj):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# object handled itself, don't proceed\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, {}\n\u001b[1;32m    152\u001b[0m format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmimebundle_formatter(obj, include\u001b[38;5;241m=\u001b[39minclude, exclude\u001b[38;5;241m=\u001b[39mexclude)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/decorator.py:231\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfun\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m--> 231\u001b[0m         args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m caller(func, \u001b[38;5;241m*\u001b[39m(extras \u001b[38;5;241m+\u001b[39m args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/site-packages/decorator.py:203\u001b[0m, in \u001b[0;36mfix\u001b[0;34m(args, kwargs, sig)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfix\u001b[39m(args, kwargs, sig):\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Fix args and kwargs to be consistent with the signature\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     ba \u001b[38;5;241m=\u001b[39m sig\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    204\u001b[0m     ba\u001b[38;5;241m.\u001b[39mapply_defaults()  \u001b[38;5;66;03m# needed for test_dan_schult\u001b[39;00m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ba\u001b[38;5;241m.\u001b[39margs, ba\u001b[38;5;241m.\u001b[39mkwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/dm/lib/python3.12/inspect.py:3267\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3263\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3264\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3265\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3266\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bind(args, kwargs)\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'task_name': 'train',\n",
    "    'tags': ['dev'],\n",
    "    'train': True,\n",
    "    'test': True,\n",
    "    'ckpt_path': None,\n",
    "    'seed': 12345,\n",
    "    'datamodule': {\n",
    "        '_target_': 'src.datamodules.classification_datamodule.ClassificationDataModule',\n",
    "        'dataset_name': 'adult',\n",
    "        'data_dir': '${paths.data_dir}',\n",
    "        'batch_size': 64,\n",
    "        'test_batch_size': 8,\n",
    "        'train_val_test_split': [0.7, 0.1, 0.2],\n",
    "        'num_workers': 0,\n",
    "        'pin_memory': False\n",
    "    },\n",
    "    'model': {\n",
    "        '_target_': 'src.models.classification_module.ClassificationLitModule',\n",
    "        'lr': 0.001,\n",
    "        'weight_decay': 0.0005,\n",
    "        'net': {\n",
    "            '_target_': 'src.models.components.simple_dense_net.SimpleDenseNet',\n",
    "            'input_size': 1,\n",
    "            'lin1_size': 256,\n",
    "            'lin2_size': 256,\n",
    "            'lin3_size': 256,\n",
    "            'output_size': 1,\n",
    "            'use_batchnorm': True\n",
    "        },\n",
    "        'criterion': {\n",
    "            '_target_': 'src.metrics.losses.ClassificationMixedLoss',\n",
    "            'loss_scalers': {'nll': 1, 'mmd': 0.2, 'sink': 6e-05},\n",
    "            'operands': {'x': 'rbf', 'y': 'rbf'},\n",
    "            'scalers': {'x': 1.0, 'y': 1.0},\n",
    "            'bandwidths': {'x': 10.0, 'y': 0.01}\n",
    "        },\n",
    "        'calibrator': {'_target_': 'torchuq.transform.calibrate.HistogramBinning'},\n",
    "        'kcal_kwargs': {\n",
    "            'operands': {'x': 'rbf', 'y': 'rbf'},\n",
    "            'scalers': {'x': 1.0, 'y': 1.0},\n",
    "            'bandwidths': {'x': 10.0, 'y': 0.01}\n",
    "        }\n",
    "    },\n",
    "    'callbacks': {\n",
    "        'model_checkpoint': {\n",
    "            '_target_': 'pytorch_lightning.callbacks.ModelCheckpoint',\n",
    "            'monitor': 'val/loss',\n",
    "            'mode': 'min',\n",
    "            'save_top_k': 1,\n",
    "            'save_last': True,\n",
    "            'verbose': False,\n",
    "            'dirpath': 'checkpoints/',\n",
    "            'filename': 'epoch_{epoch:03d}',\n",
    "            'auto_insert_metric_name': False\n",
    "        },\n",
    "        'early_stopping': {\n",
    "            '_target_': 'pytorch_lightning.callbacks.EarlyStopping',\n",
    "            'monitor': 'val/loss',\n",
    "            'mode': 'min',\n",
    "            'patience': 30,\n",
    "            'min_delta': 0\n",
    "        },\n",
    "        'model_summary': {\n",
    "            '_target_': 'pytorch_lightning.callbacks.RichModelSummary',\n",
    "            'max_depth': -1\n",
    "        },\n",
    "        'rich_progress_bar': {\n",
    "            '_target_': 'pytorch_lightning.callbacks.RichProgressBar'\n",
    "        }\n",
    "    },\n",
    "    'logger': {\n",
    "        'wandb': {\n",
    "            '_target_': 'pytorch_lightning.loggers.wandb.WandbLogger',\n",
    "            'project': 'mmd_4_11',\n",
    "            'name': '${name}',\n",
    "            'save_dir': '.',\n",
    "            'offline': False,\n",
    "            'id': None,\n",
    "            'log_model': False,\n",
    "            'prefix': '',\n",
    "            'job_type': 'train',\n",
    "            'group': '',\n",
    "            'tags': ['classification', '${name}', 'hparam', '${datamodule.dataset_name}']\n",
    "        }\n",
    "    },\n",
    "    'trainer': {\n",
    "        '_target_': 'pytorch_lightning.Trainer',\n",
    "        'min_epochs': 10,\n",
    "        'max_epochs': 200,\n",
    "        'gradient_clip_val': 0.5,\n",
    "        'accelerator': 'cpu'\n",
    "\n",
    "    },\n",
    "    'paths': {\n",
    "        'root_dir': '${oc.env:PROJECT_ROOT}',\n",
    "        'data_dir': '${paths.root_dir}/data/',\n",
    "        'log_dir': '${paths.root_dir}/logs/',\n",
    "        'output_dir': '${hydra:runtime.output_dir}',\n",
    "        'work_dir': '${hydra:runtime.cwd}'\n",
    "    },\n",
    "    'extras': {\n",
    "        'ignore_warnings': False,\n",
    "        'enforce_tags': True,\n",
    "        'print_config': True\n",
    "    },\n",
    "    'name': 'classification_mixed',\n",
    "    'hparams_search': 'classification_mixed_optuna.yaml'\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DictConfig\n",
    "config = OmegaConf.create(config)\n",
    "\n",
    "# Modifying the configuration\n",
    "config.datamodule._target_ = 'ClassificationDataModule'\n",
    "config.datamodule.dataset_name = 'adult'\n",
    "config.datamodule.data_dir = 'data'\n",
    "config.model._target_ = 'ClassificationLitModule'\n",
    "config.model.net._target_ = 'SimpleDenseNet'\n",
    "config.model.criterion._target_ = 'ClassificationMixedLoss'\n",
    "config.model.calibrator._target_ = 'TemperatureScaling'\n",
    "config.logger.wandb.project = 'DM_Benchmark'\n",
    "\n",
    "# Assuming train is a function that accepts this config\n",
    "train(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "56spr4IyNK-2",
    "Db5N2b_NpHhV"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "dm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "31b53048339a44409a3070fa58421593": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_406f2f2c9a004ca492bf01d9ff75f1d7",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n",
         "text/plain": ""
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "406f2f2c9a004ca492bf01d9ff75f1d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
